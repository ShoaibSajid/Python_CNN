{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.factory import get_imdb\n",
    "from dataset.roidb import RoiDataset, detection_collate\n",
    "from loss import build_target, yolo_loss\n",
    "from cnn_python import *\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_im_data(img):\n",
    "    \"\"\"\n",
    "    Prepare image data that will be feed to network.\n",
    "\n",
    "    Arguments:\n",
    "    img -- PIL.Image object\n",
    "\n",
    "    Returns:\n",
    "    im_data -- tensor of shape (3, H, W).\n",
    "    im_info -- dictionary {height, width}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    im_info = dict()\n",
    "    im_info['width'], im_info['height'] = img.size\n",
    "\n",
    "    # resize the image\n",
    "    H, W = cfg.input_size\n",
    "    im_data = img.resize((H, W))\n",
    "\n",
    "    # to torch tensor\n",
    "    im_data = torch.from_numpy(np.array(im_data)).float() / 255\n",
    "\n",
    "    im_data = im_data.permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "    return im_data, im_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WeightLoader(object):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(WeightLoader, self).__init__()\n",
    "\t\tself.start = 0\n",
    "\t\tself.buf = None\n",
    "\t\tself.b = 'b'\n",
    "\t\tself.g = 'g'\n",
    "\t\tself.rm = 'rm'\n",
    "\t\tself.rv = 'rv'\n",
    "\t\t\n",
    "\tdef load_conv_bn(self, conv_model, bn_model):\n",
    "\n",
    "\t\t# Make directories\n",
    "\t\tPath('./weight_parameter/bn_param/bias').mkdir(parents=True, exist_ok=True)\n",
    "\t\tPath('./weight_parameter/bn_param/gamma').mkdir(parents=True, exist_ok=True)\n",
    "\t\tPath('./weight_parameter/bn_param/running_mean').mkdir(parents=True, exist_ok=True)\n",
    "\t\tPath('./weight_parameter/bn_param/running_var').mkdir(parents=True, exist_ok=True)\n",
    "\t\tPath('./weight_parameter/conv_param/w').mkdir(parents=True, exist_ok=True)\n",
    "\t\tPath('./weight_parameter/bias/').mkdir(parents=True, exist_ok=True)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tnum_w = conv_model.weight.numel()\n",
    "\t\tnum_b = bn_model.bias.numel()\n",
    "\n",
    "\t\tbn_model.bias.data.copy_(\n",
    "\t\t\ttorch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "\n",
    "\t\tif bn_model.bias.data.shape == self.scratch.params['beta0'].shape:\n",
    "\t\t\tself.scratch.params['beta0'] = bn_model.bias.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/bias/{}'.format(0), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.bias.data))\n",
    "\t\telif bn_model.bias.data.shape == self.scratch.params['beta1'].shape:\n",
    "\t\t\tself.scratch.params['beta1'] = bn_model.bias.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/bias/{}'.format(1), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.bias.data))\n",
    "\t\telif bn_model.bias.data.shape == self.scratch.params['beta2'].shape:\n",
    "\t\t\tself.scratch.params['beta2'] = bn_model.bias.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/bias/{}'.format(2), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.bias.data))\n",
    "\t\telif bn_model.bias.data.shape == self.scratch.params['beta3'].shape:\n",
    "\t\t\tself.scratch.params['beta3'] = bn_model.bias.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/bias/{}'.format(3), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.bias.data))\n",
    "\t\telif bn_model.bias.data.shape == self.scratch.params['beta4'].shape:\n",
    "\t\t\tself.scratch.params['beta4'] = bn_model.bias.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/bias/{}'.format(4), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.bias.data))\n",
    "\t\telif bn_model.bias.data.shape == self.scratch.params['beta5'].shape:\n",
    "\t\t\tself.scratch.params['beta5'] = bn_model.bias.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/bias/{}'.format(5), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.bias.data))\n",
    "\t\telif (bn_model.bias.data.shape == self.scratch.params['beta6'].shape) and self.b == \"b\":\n",
    "\t\t\tself.scratch.params['beta6'] = bn_model.bias.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/bias/{}'.format(6), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.bias.data))\n",
    "\t\t\tself.b = 'bb'\n",
    "\t\telif (self.scratch.params['beta7'].shape == bn_model.bias.data.shape) and self.b == \"bb\":\n",
    "\t\t\tself.scratch.params['beta7'] = bn_model.bias.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/bias/{}'.format(7), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.bias.data))\n",
    "\n",
    "\t\tself.start = self.start + num_b\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\tbn_model.weight.data.copy_(\n",
    "\t\t\ttorch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "\n",
    "\n",
    "\t\tif bn_model.weight.data.shape == self.scratch.params['gamma0'].shape:\n",
    "\t\t\tself.scratch.params['gamma0'] = bn_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/gamma/{}'.format(0), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.weight.data))\n",
    "\t\telif bn_model.weight.data.shape == self.scratch.params['gamma1'].shape:\n",
    "\t\t\tself.scratch.params['gamma1'] = bn_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/gamma/{}'.format(1), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.weight.data))\n",
    "\t\telif bn_model.weight.data.shape == self.scratch.params['gamma2'].shape:\n",
    "\t\t\tself.scratch.params['gamma2'] = bn_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/gamma/{}'.format(2), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.weight.data))\n",
    "\t\telif bn_model.weight.data.shape == self.scratch.params['gamma3'].shape:\n",
    "\t\t\tself.scratch.params['gamma3'] = bn_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/gamma/{}'.format(3), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.weight.data))\n",
    "\t\telif bn_model.weight.data.shape == self.scratch.params['gamma4'].shape:\n",
    "\t\t\tself.scratch.params['gamma4'] = bn_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/gamma/{}'.format(4), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.weight.data))\n",
    "\t\telif bn_model.weight.data.shape == self.scratch.params['gamma5'].shape:\n",
    "\t\t\tself.scratch.params['gamma5'] = bn_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/gamma/{}'.format(5), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.weight.data))\n",
    "\t\telif (bn_model.weight.shape == self.scratch.params['gamma6'].shape) and self.g == \"g\":\n",
    "\t\t\tself.scratch.params['gamma6'] = bn_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/gamma/{}'.format(6), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.weight.data))\n",
    "\t\t\tself.g = 'gg'\n",
    "\t\telif (self.scratch.params['gamma7'].shape == bn_model.weight.data.shape) and self.g == \"gg\":\n",
    "\t\t\tself.scratch.params['gamma7'] = bn_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/gamma/{}'.format(7), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.weight.data))\n",
    "\n",
    "\t\tself.start = self.start + num_b\n",
    "\n",
    "\t\tbn_model.running_mean.copy_(\n",
    "\t\t\ttorch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "\n",
    "\t\tif bn_model.running_mean.data.shape == self.scratch.bn_params[0]['running_mean'].shape:\n",
    "\t\t\tself.scratch.bn_params[0]['running_mean'] = bn_model.running_mean.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_mean/{}'.format(0), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_mean.data))\n",
    "\t\telif bn_model.running_mean.data.shape == self.scratch.bn_params[1]['running_mean'].shape:\n",
    "\t\t\tself.scratch.bn_params[1]['running_mean'] = bn_model.running_mean.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_mean/{}'.format(1), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_mean.data))\n",
    "\t\telif bn_model.running_mean.data.shape == self.scratch.bn_params[2]['running_mean'].shape:\n",
    "\t\t\tself.scratch.bn_params[2]['running_mean'] = bn_model.running_mean.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_mean/{}'.format(2), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_mean.data))\n",
    "\t\telif bn_model.running_mean.data.shape == self.scratch.bn_params[3]['running_mean'].shape:\n",
    "\t\t\tself.scratch.bn_params[3]['running_mean'] = bn_model.running_mean.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_mean/{}'.format(3), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_mean.data))\n",
    "\t\telif bn_model.running_mean.data.shape == self.scratch.bn_params[4]['running_mean'].shape:\n",
    "\t\t\tself.scratch.bn_params[4]['running_mean'] = bn_model.running_mean.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_mean/{}'.format(4), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_mean.data))\n",
    "\t\telif bn_model.running_mean.data.shape == self.scratch.bn_params[5]['running_mean'].shape:\n",
    "\t\t\tself.scratch.bn_params[5]['running_mean'] = bn_model.running_mean.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_mean/{}'.format(5), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_mean.data))\n",
    "\t\telif bn_model.running_mean.data.shape == self.scratch.bn_params[6]['running_mean'].shape and self.rm == \"rm\":\n",
    "\t\t\tself.scratch.bn_params[6]['running_mean'] = bn_model.running_mean.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_mean/{}'.format(6), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_mean.data))\n",
    "\t\t\tself.rm = \"rmrm\"\n",
    "\t\telif bn_model.running_mean.data.shape == self.scratch.bn_params[7]['running_mean'].shape and self.rm == \"rmrm\":\n",
    "\t\t\tself.scratch.bn_params[7]['running_mean'] = bn_model.running_mean.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_mean/{}'.format(7), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_mean.data))\n",
    "\n",
    "\t\tself.start = self.start + num_b\n",
    "\n",
    "\t\tbn_model.running_var.copy_(\n",
    "\t\t\ttorch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "\n",
    "\t\tif bn_model.running_var.data.shape == self.scratch.bn_params[0]['running_var'].shape:\n",
    "\t\t\tself.scratch.bn_params[0]['running_var'] = bn_model.running_var.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_var/{}'.format(0), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_var.data))\n",
    "\t\telif bn_model.running_var.data.shape == self.scratch.bn_params[1]['running_var'].shape:\n",
    "\t\t\tself.scratch.bn_params[1]['running_var'] = bn_model.running_var.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_var/{}'.format(1), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_var.data))\n",
    "\t\telif bn_model.running_var.data.shape == self.scratch.bn_params[2]['running_var'].shape:\n",
    "\t\t\tself.scratch.bn_params[2]['running_var'] = bn_model.running_var.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_var/{}'.format(2), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_var.data))\n",
    "\t\telif bn_model.running_var.data.shape == self.scratch.bn_params[3]['running_var'].shape:\n",
    "\t\t\tself.scratch.bn_params[3]['running_var'] = bn_model.running_var.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_var/{}'.format(3), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_var.data))\n",
    "\t\telif bn_model.running_var.data.shape == self.scratch.bn_params[4]['running_var'].shape:\n",
    "\t\t\tself.scratch.bn_params[4]['running_var'] = bn_model.running_var.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_var/{}'.format(4), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_var.data))\n",
    "\t\telif bn_model.running_var.data.shape == self.scratch.bn_params[5]['running_var'].shape:\n",
    "\t\t\tself.scratch.bn_params[5]['running_var'] = bn_model.running_var.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_var/{}'.format(5), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_var.data))\n",
    "\t\telif bn_model.running_var.data.shape == self.scratch.bn_params[6]['running_var'].shape and self.rv == \"rv\":\n",
    "\t\t\tself.scratch.bn_params[6]['running_var'] = bn_model.running_var.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_var/{}'.format(6), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_var.data))\n",
    "\t\t\tself.rv = \"rvrv\"\n",
    "\t\telif bn_model.running_var.data.shape == self.scratch.bn_params[7]['running_var'].shape and self.rv == \"rvrv\":\n",
    "\t\t\tself.scratch.bn_params[7]['running_var'] = bn_model.running_var.data\n",
    "\t\t\twith open('./weight_parameter/bn_param/running_var/{}'.format(7), mode='w') as f:\n",
    "\t\t\t\tf.write(str(bn_model.running_var.data))\n",
    "\t\t\t\n",
    "\t\tself.start = self.start + num_b\n",
    "\n",
    "\t\tconv_model.weight.data.copy_(\n",
    "\t\t\ttorch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_w]), conv_model.weight.size()))\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tif conv_model.weight.data.shape == (16, 3, 3, 3):\n",
    "\t\t\tself.scratch.params['W0'] = conv_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/conv_param/w/{}'.format(0), mode='w') as f:\n",
    "\t\t\t\tf.write(str(conv_model.weight.data))\n",
    "\t\telif conv_model.weight.data.shape == (32, 16, 3, 3):\n",
    "\t\t\tself.scratch.params['W1'] = conv_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/conv_param/w/{}'.format(1), mode='w') as f:\n",
    "\t\t\t\tf.write(str(conv_model.weight.data))\n",
    "\t\telif conv_model.weight.data.shape == (64, 32, 3, 3):\n",
    "\t\t\tself.scratch.params['W2'] = conv_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/conv_param/w/{}'.format(2), mode='w') as f:\n",
    "\t\t\t\tf.write(str(conv_model.weight.data))\n",
    "\t\telif conv_model.weight.data.shape == (128, 64, 3, 3):\n",
    "\t\t\tself.scratch.params['W3'] = conv_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/conv_param/w/{}'.format(3), mode='w') as f:\n",
    "\t\t\t\tf.write(str(conv_model.weight.data))\n",
    "\t\telif conv_model.weight.data.shape == (256, 128, 3, 3):\n",
    "\t\t\tself.scratch.params['W4'] = conv_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/conv_param/w/{}'.format(4), mode='w') as f:\n",
    "\t\t\t\tf.write(str(conv_model.weight.data))\n",
    "\t\telif conv_model.weight.data.shape == (512, 256, 3, 3):\n",
    "\t\t\tself.scratch.params['W5'] = conv_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/conv_param/w/{}'.format(5), mode='w') as f:\n",
    "\t\t\t\tf.write(str(conv_model.weight.data))\n",
    "\t\telif conv_model.weight.data.shape == (1024, 512, 3, 3):            \n",
    "\t\t\tself.scratch.params['W6'] = conv_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/conv_param/w/{}'.format(6), mode='w') as f:\n",
    "\t\t\t\tf.write(str(conv_model.weight.data))\n",
    "\t\telif conv_model.weight.data.shape == (1024, 1024, 3, 3):\n",
    "\t\t\tself.scratch.params['W7'] = conv_model.weight.data\n",
    "\t\t\twith open('./weight_parameter/conv_param/w/{}'.format(7), mode='w') as f:\n",
    "\t\t\t\tf.write(str(conv_model.weight.data))\n",
    "\t\tself.start = self.start + num_w\n",
    "\n",
    "\tdef load_conv(self, conv_model):\n",
    "\t\tnum_w = conv_model.weight.numel()\n",
    "\t\tnum_b = conv_model.bias.numel()\n",
    "\t\tconv_model.bias.data.copy_(\n",
    "\t\t\ttorch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), conv_model.bias.size()))\n",
    "\t\tself.scratch.params['b8'] = conv_model.bias.data\n",
    "\t\twith open('./weight_parameter/bias/{}'.format(7), mode='w') as f:\n",
    "\t\t\tf.write(str(conv_model.bias.data))\n",
    "\t\tself.start = self.start + num_b\n",
    "\t\tconv_model.weight.data.copy_(\n",
    "\t\t\ttorch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_w]), conv_model.weight.size()))\n",
    "\t\tself.scratch.params['W8'] = conv_model.weight.data\n",
    "\t\twith open('./weight_parameter/conv_param/w/{}'.format(8), mode='w') as f:\n",
    "\t\t\tf.write(str(conv_model.weight.data))\n",
    "\t\tself.start = self.start + num_w\n",
    "\n",
    "\tdef dfs(self, m):\n",
    "\t\tchildren = list(m.children())\n",
    "\t\tfor i, c in enumerate(children):\n",
    "\t\t\tif isinstance(c, torch.nn.Sequential):\n",
    "\t\t\t\tself.dfs(c)\n",
    "\t\t\telif isinstance(c, torch.nn.Conv2d):\n",
    "\t\t\t\tif c.bias is not None:\n",
    "\t\t\t\t\tself.load_conv(c)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.load_conv_bn(c, children[i + 1])\n",
    "\n",
    "\tdef load(self, model_to_load_weights_to, model, weights_file):\n",
    "\t\tself.scratch = model_to_load_weights_to \n",
    "\t\tself.start = 0\n",
    "\t\tfp = open(weights_file, 'rb')\n",
    "\t\theader = np.fromfile(fp, count=4, dtype=np.int32)\n",
    "\t\tself.buf = np.fromfile(fp, dtype=np.float32)\n",
    "\t\tfp.close()\n",
    "\t\tsize = self.buf.size\n",
    "\t\tself.dfs(model)\n",
    "\t\t# make sure the loaded weight is right\n",
    "\t\tassert size == self.start\n",
    "\t\treturn self.scratch\n",
    "\n",
    "python_model = DeepConvNet(input_dims=(3, 416, 416),\n",
    "                        num_filters=[16, 32, 64, 128, 256, 512, 1024, 1024],\n",
    "                        max_pools=[0, 1, 2, 3, 4],\n",
    "                        weight_scale='kaiming',\n",
    "                        batchnorm=True,\n",
    "                        dtype=torch.float32, device='cpu')\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_Load_Weights = True\n",
    "if _Load_Weights:\n",
    "\tclass Yolov2(nn.Module):\n",
    "\n",
    "\t\tnum_classes = 20\n",
    "\t\tnum_anchors = 5\n",
    "\n",
    "\t\tdef __init__(self, classes=None, weights_file=False):\n",
    "\t\t\tsuper(Yolov2, self).__init__()\n",
    "\t\t\tif classes:\n",
    "\t\t\t\tself.num_classes = len(classes)\n",
    "\n",
    "\n",
    "\t\t\tself.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\t\t\tself.lrelu = nn.LeakyReLU(0.1, inplace=True)\n",
    "\t\t\tself.slowpool = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "\n",
    "\t\t\t\n",
    "\t\t\tself.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\t\t\tself.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "\t\t\tself.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\t\t\tself.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "\t\t\tself.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\t\t\tself.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "\t\t\tself.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\t\t\tself.bn4 = nn.BatchNorm2d(128)\n",
    "\n",
    "\t\t\tself.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\t\t\tself.bn5 = nn.BatchNorm2d(256)\n",
    "\n",
    "\t\t\tself.conv6 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\t\t\tself.bn6 = nn.BatchNorm2d(512)\n",
    "\n",
    "\t\t\tself.conv7 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\t\t\tself.bn7 = nn.BatchNorm2d(1024)\n",
    "\n",
    "\t\t\tself.conv8 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\t\t\tself.bn8 = nn.BatchNorm2d(1024)\n",
    "\n",
    "\t\t\tself.conv9 = nn.Conv2d(1024, (5 + self.num_classes) * self.num_anchors, kernel_size=1)\n",
    "\n",
    "\n",
    "\t\tdef forward(self, x, gt_boxes=None, gt_classes=None, num_boxes=None, training=False):\n",
    "\t\t\t\"\"\"\n",
    "\t\t\tx: Variable\n",
    "\t\t\tgt_boxes, gt_classes, num_boxes: Tensor\n",
    "\t\t\t\"\"\"\n",
    "\n",
    "\t\t\tx = self.maxpool(self.lrelu(self.bn1(self.conv1(x))))\n",
    "\t\t\tx = self.maxpool(self.lrelu(self.bn2(self.conv2(x))))\n",
    "\t\t\tx = self.maxpool(self.lrelu(self.bn3(self.conv3(x))))\n",
    "\t\t\tx = self.maxpool(self.lrelu(self.bn4(self.conv4(x))))\n",
    "\t\t\tx = self.maxpool(self.lrelu(self.bn5(self.conv5(x))))\n",
    "\t\t\tx = self.lrelu(self.bn6(self.conv6(x)))\n",
    "\t\t\tx = F.pad(x, (0, 1, 0, 1))\n",
    "\t\t\tx = self.slowpool(x)\n",
    "\t\t\tx = self.lrelu(self.bn7(self.conv7(x)))\n",
    "\t\t\tx = self.lrelu(self.bn8(self.conv8(x)))\n",
    "\t\t\tout = self.conv9(x)\n",
    "\n",
    "\n",
    "\n",
    "\t\t\t# out -- tensor of shape (B, num_anchors * (5 + num_classes), H, W)\n",
    "\t\t\tbsize, _, h, w = out.size()\n",
    "\n",
    "\t\t\t# 5 + num_class tensor represents (t_x, t_y, t_h, t_w, t_c) and (class1_score, class2_score, ...)\n",
    "\t\t\t# reorganize the output tensor to shape (B, H * W * num_anchors, 5 + num_classes)\n",
    "\t\t\tout = out.permute(0, 2, 3, 1).contiguous().view(bsize, h * w * self.num_anchors, 5 + self.num_classes)\n",
    "\n",
    "\t\t\t# activate the output tensor\n",
    "\t\t\t# `sigmoid` for t_x, t_y, t_c; `exp` for t_h, t_w;\n",
    "\t\t\t# `softmax` for (class1_score, class2_score, ...)\n",
    "\n",
    "\t\t\txy_pred = torch.sigmoid(out[:, :, 0:2])\n",
    "\t\t\tconf_pred = torch.sigmoid(out[:, :, 4:5])\n",
    "\t\t\thw_pred = torch.exp(out[:, :, 2:4])\n",
    "\t\t\tclass_score = out[:, :, 5:]\n",
    "\t\t\tclass_pred = F.softmax(class_score, dim=-1)\n",
    "\t\t\tdelta_pred = torch.cat([xy_pred, hw_pred], dim=-1)\n",
    "\n",
    "\t\t\tif training:\n",
    "\t\t\t\toutput_variable = (delta_pred, conf_pred, class_score)\n",
    "\t\t\t\toutput_data = [v.data for v in output_variable]\n",
    "\t\t\t\tgt_data = (gt_boxes, gt_classes, num_boxes)\n",
    "\t\t\t\ttarget_data = build_target(output_data, gt_data, h, w)\n",
    "\n",
    "\t\t\t\ttarget_variable = [v for v in target_data]\n",
    "\t\t\t\tbox_loss, iou_loss, class_loss = yolo_loss(output_variable, target_variable)\n",
    "\n",
    "\t\t\t\treturn box_loss, iou_loss, class_loss\n",
    "\n",
    "\n",
    "\t\t\treturn delta_pred, conf_pred, class_pred\n",
    "\tmodel = Yolov2()\n",
    "\tweightloader = WeightLoader()\n",
    "\tpython_model = weightloader.load(python_model, model, './data/pretrained/yolov2-tiny-voc.weights')\n",
    "\t# weightloader.load(model, self.scratch_torch, './yolov2-tiny-voc.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "_Dataset = False\n",
    "if _Dataset:\n",
    "\tdataset = 'voc0712trainval'\n",
    "\timdb_name = 'voc_2007_trainval+voc_2012_trainval'\n",
    "\timdbval_name ='voc_2007_test'\n",
    "\n",
    "\tdef axpy(N: int = 0., ALPHA: float = 1., X: int = 0, INCX: int = 1, Y: float =0., INCY: int = 1):\n",
    "\t\tfor i in range(N):\n",
    "\t\t\tY[i * INCY] += ALPHA * X[i * INCX]\n",
    "\n",
    "\tdef get_dataset(datasetnames):\n",
    "\t\tnames = datasetnames.split('+')\n",
    "\t\tdataset = RoiDataset(get_imdb(names[0]))\n",
    "\t\tprint('load dataset {}'.format(names[0]))\n",
    "\t\tfor name in names[1:]:\n",
    "\t\t\ttmp = RoiDataset(get_imdb(name))\n",
    "\t\t\tdataset += tmp\n",
    "\t\t\tprint('load and add dataset {}'.format(name))\n",
    "\t\treturn dataset\n",
    "\n",
    "\ttrain_dataset = get_dataset(imdb_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_Dataloader = _Dataset\n",
    "if _Dataloader:\n",
    "\ttrain_dataloader = DataLoader(train_dataset, batch_size=64,\n",
    "\t\t\t\t\t\t\t\t\tshuffle=True, num_workers=2,\n",
    "\t\t\t\t\t\t\t\t\tcollate_fn=detection_collate, drop_last=True)\n",
    "\ttrain_data_iter = iter(train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_Get_Next_Data = _Dataloader\n",
    "if _Get_Next_Data:\n",
    "\t_data = next(train_data_iter)\n",
    "\tim_data, gt_boxes, gt_classes, num_obj = _data\n",
    "\n",
    "\tim_data     = im_data[0].unsqueeze(0)\n",
    "\tgt_boxes    = gt_boxes[0].unsqueeze(0)\n",
    "\tgt_classes  = gt_classes[0].unsqueeze(0)\n",
    "\tnum_obj     = num_obj[0].unsqueeze(0)\n",
    " \n",
    "\t__data = im_data, gt_boxes, gt_classes, num_obj\n",
    "\n",
    "\tPath(\"Temp_Files\").mkdir(parents=True, exist_ok=True)\n",
    "\twith open('Temp_Files/default_data.pickle','wb') as handle:\n",
    "\t\tpickle.dump(_data,handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "\twith open('Temp_Files/default_data.pickle', 'rb') as handle:\n",
    "\t\tb = pickle.load(handle)\n",
    "\tim_data, gt_boxes, gt_classes, num_obj = b\n",
    "\tim_data, gt_boxes, gt_classes, num_obj = im_data[0].unsqueeze(0), gt_boxes[0].unsqueeze(0), gt_classes[0].unsqueeze(0), num_obj[0].unsqueeze(0)\n",
    "\t__data = im_data, gt_boxes, gt_classes, num_obj\n",
    "\tprint(f\"\\n\\nLoading data from saved file\\n\\nImage (im_data[0,:3,66:69,66:69]\\n{im_data[0,:3,66:69,66:69]}\\n\\n\")\n",
    "\t\n",
    "\n",
    "    # im = np.random.randn(1, 3, 416, 416)\n",
    "\n",
    "    # box_loss, iou_loss, class_loss = scratch.loss(im_data, gt_boxes=gt_boxes, gt_classes=gt_classes, num_boxes=num_obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    Fout, Fcache, loss, loss_grad, BlDout, Bgrads = python_model.train(im_data, gt_boxes=gt_boxes, gt_classes=gt_classes, num_boxes=num_obj)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
