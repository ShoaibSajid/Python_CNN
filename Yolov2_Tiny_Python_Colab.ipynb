{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYruBIRQYRBT82PFXJL0W6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShoaibSajid/Python_CNN/blob/Yolov2-Tiny/Yolov2_Tiny_Python_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHbi2rxSAPqg",
        "outputId": "15034ca4-92d0-4a89-da82-fb0577365382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Github Repo exist.\n",
            "/content/Python_CNN\n",
            "Already on 'Yolov2-Tiny'\n",
            "Your branch is up to date with 'origin/Yolov2-Tiny'.\n",
            "Default Input data already exists\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), 467 bytes | 155.00 KiB/s, done.\n",
            "From https://github.com/ShoaibSajid/Python_CNN\n",
            "   c205ef8..8835e83  Yolov2-Tiny -> origin/Yolov2-Tiny\n",
            "Updating c205ef8..8835e83\n",
            "Fast-forward\n",
            " cnn_python.py        | 18 \u001b[32m+++++++++\u001b[m\u001b[31m---------\u001b[m\n",
            " yolov2tiny_python.py | 12 \u001b[32m++++++\u001b[m\u001b[31m------\u001b[m\n",
            " 2 files changed, 15 insertions(+), 15 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "![ ! -d \"./Python_CNN\" ] && echo \"Github Repo DOES NOT exists.\"\n",
        "![ ! -d \"./Python_CNN\" ] && git clone https://github.com/ShoaibSajid/Python_CNN\n",
        "![ -d \"./Python_CNN\" ] && echo \"Github Repo exist.\"\n",
        "%cd Python_CNN\n",
        "!git checkout Yolov2-Tiny\n",
        "# %pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "# %pip install tqdm matplotlib mnist==0.2.2 numpy bz2file\n",
        "# !pip install --upgrade --no-cache-dir gdown\n",
        "![ -e \"./Input_Data.pickle\" ] && echo 'Default Input data already exists'\n",
        "![ ! -e \"./Input_Data.pickle\" ] && echo 'Default Input data is missing. Downloading file.'\n",
        "![ ! -e \"./Input_Data.pickle\" ] && gdown --id 1B8hlZbsewj4RbEVM59yce0M3Nyz54KFQ\n",
        "! git pull"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!echo \n",
        "!echo List of files\n",
        "!echo \n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF5lKGtiBKle",
        "outputId": "72107e47-10ee-48c8-a9d1-5631269fd988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Python_CNN\n",
            "\n",
            "List of files\n",
            "\n",
            "cnn_python.py\t   Jupyter_Notebook_CNN_Python.ipynb  Temp_Files\n",
            "cnn_torch.py\t   LICENSE\t\t\t      util\n",
            "config\t\t   loss.py\t\t\t      weight_parameter\n",
            "data\t\t   Outputs\t\t\t      yolov2tiny_python.py\n",
            "dataset\t\t   __pycache__\t\t\t      yolov2tiny_torch.py\n",
            "eecs598\t\t   README.md\n",
            "Input_Data.pickle  readme_src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from cnn_python import *"
      ],
      "metadata": {
        "id": "NuT2xAjBAzPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python_model = DeepConvNet(input_dims=(3, 416, 416),\n",
        "\t\t\t\t\t\tnum_filters=[16, 32, 64, 128, 256, 512, 1024, 1024],\n",
        "\t\t\t\t\t\tmax_pools=[0, 1, 2, 3, 4],\n",
        "\t\t\t\t\t\tweight_scale='kaiming',\n",
        "\t\t\t\t\t\tbatchnorm=True,\n",
        "\t\t\t\t\t\tdtype=torch.float32, device='cpu')"
      ],
      "metadata": {
        "id": "kyq2PMOGBzfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_Load_Weights = True\n",
        "if _Load_Weights:\n",
        "\tmodel = Yolov2()\n",
        "\tweightloader = WeightLoader()\n",
        "\tpython_model = weightloader.load(python_model, model, './data/pretrained/yolov2-tiny-voc.weights')\n"
      ],
      "metadata": {
        "id": "ugUD6u7SB0se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_Dataset = False\n",
        "if _Dataset:\n",
        "\tfrom dataset.factory import get_imdb\n",
        "\tfrom dataset.roidb import RoiDataset, detection_collate\n",
        "\tdataset = 'voc0712trainval'\n",
        "\timdb_name = 'voc_2007_trainval+voc_2012_trainval'\n",
        "\timdbval_name ='voc_2007_test'\n",
        "\n",
        "\tdef axpy(N: int = 0., ALPHA: float = 1., X: int = 0, INCX: int = 1, Y: float =0., INCY: int = 1):\n",
        "\t\tfor i in range(N):\n",
        "\t\t\tY[i * INCY] += ALPHA * X[i * INCX]\n",
        "\n",
        "\tdef get_dataset(datasetnames):\n",
        "\t\tnames = datasetnames.split('+')\n",
        "\t\tdataset = RoiDataset(get_imdb(names[0]))\n",
        "\t\tprint('load dataset {}'.format(names[0]))\n",
        "\t\tfor name in names[1:]:\n",
        "\t\t\ttmp = RoiDataset(get_imdb(name))\n",
        "\t\t\tdataset += tmp\n",
        "\t\t\tprint('load and add dataset {}'.format(name))\n",
        "\t\treturn dataset\n",
        "\n",
        "\ttrain_dataset = get_dataset(imdb_name)\n"
      ],
      "metadata": {
        "id": "NQmiyJUdChV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_Dataloader = _Dataset\n",
        "if _Dataloader:\n",
        "\ttrain_dataloader = DataLoader(train_dataset, batch_size=64,\n",
        "\t\t\t\t\t\t\t\t\tshuffle=True, num_workers=2,\n",
        "\t\t\t\t\t\t\t\t\tcollate_fn=detection_collate, drop_last=True)\n",
        "\ttrain_data_iter = iter(train_dataloader)\n"
      ],
      "metadata": {
        "id": "M61h9QHzEGe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_Get_Next_Data = _Dataloader\n",
        "if _Get_Next_Data:\n",
        "\t_data = next(train_data_iter)\n",
        "\tim_data, gt_boxes, gt_classes, num_boxes = _data\n",
        "\n",
        "\tim_data     = im_data[0].unsqueeze(0)\n",
        "\tgt_boxes    = gt_boxes[0].unsqueeze(0)\n",
        "\tgt_classes  = gt_classes[0].unsqueeze(0)\n",
        "\tnum_boxes     = num_boxes[0].unsqueeze(0)\n",
        "\n",
        "\t__data = im_data, gt_boxes, gt_classes, num_boxes\n",
        "\n",
        "\t# Path(\"Input\").mkdir(parents=True, exist_ok=True)\n",
        "\twith open('Input_Data.pickle','wb') as handle:\n",
        "\t\tpickle.dump(__data,handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "else:\n",
        "\tdefault_data = 'Input_Data.pickle'\n",
        "\t# if not os.path.isfile(default_data):\n",
        "\t# \tprint('Deafult data file does not exist. Downlaoding file now.')\n",
        "\t# \turl = 'https://drive.google.com/uc?id=1j1zyq0lRQ_BVqSS5zM2GHU3Q4c1qH0DP'\n",
        "\t# \toutput = default_data\n",
        "\t# \tgdown.download(url, output, quiet=False)\n",
        "\twith open(default_data, 'rb') as handle:\n",
        "\t\tb = pickle.load(handle)\n",
        "\tim_data, gt_boxes, gt_classes, num_boxes = b\n",
        "\t__data = im_data, gt_boxes, gt_classes, num_boxes\n",
        "\tprint(f\"\\n\\nLoading data from saved file\\n\\nImage (im_data[0,:3,66:69,66:69]\\n{im_data[0,:3,66:69,66:69]}\\n\\n\")\n",
        "\t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otRW0SGVED3z",
        "outputId": "31652d14-575e-403a-c7cb-bad974cbef09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Loading data from saved file\n",
            "\n",
            "Image (im_data[0,:3,66:69,66:69]\n",
            "tensor([[[0.6431, 0.6431, 0.6392],\n",
            "         [0.6431, 0.6431, 0.6431],\n",
            "         [0.6471, 0.6471, 0.6471]],\n",
            "\n",
            "        [[0.7373, 0.7373, 0.7333],\n",
            "         [0.7373, 0.7373, 0.7412],\n",
            "         [0.7412, 0.7412, 0.7373]],\n",
            "\n",
            "        [[1.0000, 1.0000, 1.0000],\n",
            "         [1.0000, 1.0000, 1.0000],\n",
            "         [1.0000, 1.0000, 1.0000]]])\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8GPhER35JB1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define flags\n",
        "python_model.forward_prop \t= True  \t# Perform forward propagation or load saved file.\n",
        "python_model.cal_loss \t\t  = True    # Perform loss calculation or load save file\n",
        "python_model.backward_prop \t= True  \t# Perform backward propagation or load saved file\n",
        "python_model.save_pickle \t  = True  \t# Save output in form of pickle file\n",
        "python_model.save_output \t  = True   \t# Save output in form of text files"
      ],
      "metadata": {
        "id": "36GdGs3uJB6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Method 1**"
      ],
      "metadata": {
        "id": "1wSk5x9nInSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward, Loss and Backward\n",
        "# Fout, Fcache, loss, loss_grad, BlDout, Bgrads = python_model.train(im_data, gt_boxes=gt_boxes, gt_classes=gt_classes, num_boxes=num_boxes)"
      ],
      "metadata": {
        "id": "FV51G37lFsbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Method 2**"
      ],
      "metadata": {
        "id": "85yArUbWIk6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward Propagation\n",
        "X = im_data\n",
        "if python_model.forward_prop:\n",
        "  \n",
        "  out, cache, FOut = python_model.forward(X)\n",
        "\n",
        "  Path(\"Temp_Files/Python\").mkdir(parents=True, exist_ok=True)\n",
        "  with open('Temp_Files/Python/Forward_Out_last_layer.pickle','wb') as handle:\n",
        "    pickle.dump(out,handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  with open('Temp_Files/Python/Forward_cache.pickle','wb') as handle:\n",
        "    pickle.dump(cache,handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  with open('Temp_Files/Python/Forward_Out_all_layers.pickle','wb') as handle:\n",
        "    pickle.dump(FOut,handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "else:\n",
        "  print(\"Loading previous files for Forward Propagation.\")\n",
        "  with open('Temp_Files/Python/Forward_Out_last_layer.pickle', 'rb') as handle:\n",
        "    out = pickle.load(handle)\n",
        "    out.requires_grad = True\n",
        "    out.retain_grad()\n",
        "  with open('Temp_Files/Python/Forward_Out_all_layers.pickle','rb') as handle:\n",
        "    FOut = pickle.load(handle)\n",
        "  with open('Temp_Files/Python/Forward_cache.pickle', 'rb') as handle:\n",
        "    cache = pickle.load(handle)\n",
        "   "
      ],
      "metadata": {
        "id": "QmwrxbtrHHhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Loss\n",
        "if python_model.cal_loss:\n",
        "  loss,   loss_grad = python_model.loss(out, gt_boxes=gt_boxes, gt_classes=gt_classes, num_boxes=num_boxes)\n",
        "  with open('Temp_Files/Python/loss.pickle','wb') as handle:\n",
        "    pickle.dump(loss,handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  with open('Temp_Files/Python/loss_gradients.pickle','wb') as handle:\n",
        "    pickle.dump(loss_grad,handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "else:\n",
        "  print(\"Loading previous files for Loss Calculation.\")\n",
        "  with open('Temp_Files/Python/loss.pickle', 'rb') as handle:\n",
        "    loss = pickle.load(handle)\n",
        "  with open('Temp_Files/Python/loss_gradients.pickle', 'rb') as handle:\n",
        "    loss_grad = pickle.load(handle)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQILM8CTI453",
        "outputId": "2a7b3da8-131b-4ec3-df5a-2753609716c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating the loss and its gradients for python model.\n",
            "\n",
            "Loss = 13.85721206665039\n",
            "\n",
            "\n",
            "\n",
            "Loss Gradients\n",
            "\ttorch.float32\n",
            "\ttensor([ 6.5163e-02, -1.5547e-02,  6.2194e-02,  1.6630e-01,  1.0815e-07,\n",
            "         1.1848e-06,  2.0847e-06,  3.1208e-07,  2.2008e-06,  3.5474e-06])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward Propagation\n",
        "if python_model.backward_prop:   \n",
        "  lDout, grads = python_model.backward(loss_grad, cache)\n",
        "  with open('Temp_Files/Python/Backward_lDout.pickle','wb') as handle:\n",
        "    pickle.dump(lDout,handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  with open('Temp_Files/Python/Backward_grads.pickle','wb') as handle:\n",
        "    pickle.dump(grads,handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "else:\n",
        "  print(\"Loading previous files for Backward Propagation.\")\n",
        "  with open('Temp_Files/Python/Backward_lDout.pickle', 'rb') as handle:\n",
        "    lDout = pickle.load(handle)\n",
        "  with open('Temp_Files/Python/Backward_grads.pickle', 'rb') as handle:\n",
        "    grads = pickle.load(handle)\n"
      ],
      "metadata": {
        "id": "kBi7seVsJYtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save Outputs**"
      ],
      "metadata": {
        "id": "VhWv9DebJkF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save output for circuit team.\n",
        "if python_model.save_output:\n",
        "  save_txt(f'Outputs/Python/Forward/Out_Last_Layer'  , out)\n",
        "  save_txt(f'Outputs/Python/Forward/Out_Layer'       , FOut)\n",
        "  # save_txt(f'Outputs/Python/Forward/cache_Layer'     , cache)\n",
        "  save_txt(f'Outputs/Python/Loss/loss'               , loss)\n",
        "  save_txt(f'Outputs/Python/Loss/loss_grad'          , loss_grad)\n",
        "  save_txt(f'Outputs/Python/Backward/lDout_Layer'    , lDout)\n",
        "  save_txt(f'Outputs/Python/Backward/grads'          , grads)\n",
        "  save_txt(f'Outputs/Python/Parameters/'             , python_model.params)\n",
        "  save_txt(f'Outputs/Python/Input_Image'             , X)\n",
        "  print('Outputs have been saved')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veeczoNvJjh2",
        "outputId": "b0431ff5-154c-429b-bda7-7f2f76307e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t\t--> Saved Outputs/Python/Forward/Out_Last_Layer.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Forward/Out_Layer_0.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Forward/Out_Layer_1.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Forward/Out_Layer_2.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Forward/Out_Layer_3.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Forward/Out_Layer_4.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Forward/Out_Layer_5.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Forward/Out_Layer_60.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Forward/Out_Layer_61.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Forward/Out_Layer_6.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Forward/Out_Layer_7.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Forward/Out_Layer_8.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Loss/loss.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Loss/loss_grad.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/lDout_Layer_8.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/lDout_Layer_7.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/lDout_Layer_6.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/lDout_Layer_5.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/lDout_Layer_4.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/lDout_Layer_3.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/lDout_Layer_2.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/lDout_Layer_1.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/lDout_Layer_0.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_W8.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_b8.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_W7.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_gamma7.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_beta7.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_W6.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_gamma6.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_beta6.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_W5.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_gamma5.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_beta5.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_W4.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_gamma4.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_beta4.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_W3.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_gamma3.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_beta3.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_W2.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_gamma2.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_beta2.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_W1.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_gamma1.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_beta1.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_W0.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_gamma0.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Backward/grads_beta0.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_mean0.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_var0.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_gamma0.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_beta0.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_W0.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_mean1.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_var1.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_gamma1.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_beta1.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_W1.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_mean2.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_var2.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_gamma2.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_beta2.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_W2.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_mean3.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_var3.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_gamma3.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_beta3.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_W3.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_mean4.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_var4.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_gamma4.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_beta4.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_W4.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_mean5.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_var5.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_gamma5.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_beta5.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_W5.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_mean6.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_var6.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_gamma6.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_beta6.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_W6.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_mean7.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_running_var7.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_gamma7.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_beta7.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_W7.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_W8.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Parameters/_b8.txt\n",
            "\n",
            "\t\t--> Saved Outputs/Python/Input_Image.txt\n",
            "Outputs have been saved\n"
          ]
        }
      ]
    }
  ]
}