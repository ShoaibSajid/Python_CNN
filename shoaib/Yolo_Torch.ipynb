{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShoaibSajid/Python_CNN/blob/main/CNN_Torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %cd ~\n",
        "# ![ ! -d \"./Python_CNN\" ] && echo \"Github Repo DOES NOT exists.\"\n",
        "# ![ ! -d \"./Python_CNN\" ] && git clone https://github.com/ShoaibSajid/Python_CNN\n",
        "# ![ -d \"./Python_CNN\" ] && echo \"Github Repo exist.\"\n",
        "# %cd Python_CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'yolov2tiny'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/home/gpuadmin/Shoaib/Python_CNN/shoaib/Yolo_Torch.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223231302e3132352e3135302e34302d4750552d41646d696e227d/home/gpuadmin/Shoaib/Python_CNN/shoaib/Yolo_Torch.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223231302e3132352e3135302e34302d4750552d41646d696e227d/home/gpuadmin/Shoaib/Python_CNN/shoaib/Yolo_Torch.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223231302e3132352e3135302e34302d4750552d41646d696e227d/home/gpuadmin/Shoaib/Python_CNN/shoaib/Yolo_Torch.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39myolov2tiny\u001b[39;00m \u001b[39mimport\u001b[39;00m Yolov2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223231302e3132352e3135302e34302d4750552d41646d696e227d/home/gpuadmin/Shoaib/Python_CNN/shoaib/Yolo_Torch.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39meecs598\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223231302e3132352e3135302e34302d4750552d41646d696e227d/home/gpuadmin/Shoaib/Python_CNN/shoaib/Yolo_Torch.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcnn_scratch\u001b[39;00m \u001b[39mimport\u001b[39;00m DeepConvNet, Conv, ConvB, Conv_ReLU, Conv_ReLU_Pool, Conv_BatchNorm_ReLU, Conv_BatchNorm_ReLU_Pool\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yolov2tiny'"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from yolov2tiny import Yolov2\n",
        "import eecs598\n",
        "from cnn_scratch import DeepConvNet, Conv, ConvB, Conv_ReLU, Conv_ReLU_Pool, Conv_BatchNorm_ReLU, Conv_BatchNorm_ReLU_Pool\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cw04b-NnPF_e"
      },
      "outputs": [],
      "source": [
        "\n",
        "class WeightLoader(object):\n",
        "    def __init__(self):\n",
        "        super(WeightLoader, self).__init__()\n",
        "        self.start = 0\n",
        "        self.buf = None\n",
        "        self.b = 'b'\n",
        "        self.g = 'g'\n",
        "        self.rm = 'rm'\n",
        "        self.rv = 'rv'\n",
        "        \n",
        "    def load_conv_bn(self, conv_model, bn_model):\n",
        "\n",
        "        num_w = conv_model.weight.numel()\n",
        "        num_b = bn_model.bias.numel()\n",
        "\n",
        "        bn_model.bias.data.copy_(\n",
        "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
        "\n",
        "        if bn_model.bias.data.shape == scratch.params['beta0'].shape:\n",
        "            scratch.params['beta0'] = bn_model.bias.data\n",
        "            with open('./weight_parameter/bn_param/bias/{}'.format(0), mode='w') as f:\n",
        "                f.write(str(bn_model.bias.data))\n",
        "        elif bn_model.bias.data.shape == scratch.params['beta1'].shape:\n",
        "            scratch.params['beta1'] = bn_model.bias.data\n",
        "            with open('./weight_parameter/bn_param/bias/{}'.format(1), mode='w') as f:\n",
        "                f.write(str(bn_model.bias.data))\n",
        "        elif bn_model.bias.data.shape == scratch.params['beta2'].shape:\n",
        "            scratch.params['beta2'] = bn_model.bias.data\n",
        "            with open('./weight_parameter/bn_param/bias/{}'.format(2), mode='w') as f:\n",
        "                f.write(str(bn_model.bias.data))\n",
        "        elif bn_model.bias.data.shape == scratch.params['beta3'].shape:\n",
        "            scratch.params['beta3'] = bn_model.bias.data\n",
        "            with open('./weight_parameter/bn_param/bias/{}'.format(3), mode='w') as f:\n",
        "                f.write(str(bn_model.bias.data))\n",
        "        elif bn_model.bias.data.shape == scratch.params['beta4'].shape:\n",
        "            scratch.params['beta4'] = bn_model.bias.data\n",
        "            with open('./weight_parameter/bn_param/bias/{}'.format(4), mode='w') as f:\n",
        "                f.write(str(bn_model.bias.data))\n",
        "        elif bn_model.bias.data.shape == scratch.params['beta5'].shape:\n",
        "            scratch.params['beta5'] = bn_model.bias.data\n",
        "            with open('./weight_parameter/bn_param/bias/{}'.format(5), mode='w') as f:\n",
        "                f.write(str(bn_model.bias.data))\n",
        "        elif (bn_model.bias.data.shape == scratch.params['beta6'].shape) and self.b == \"b\":\n",
        "            scratch.params['beta6'] = bn_model.bias.data\n",
        "            with open('./weight_parameter/bn_param/bias/{}'.format(6), mode='w') as f:\n",
        "                f.write(str(bn_model.bias.data))\n",
        "            self.b = 'bb'\n",
        "        elif (scratch.params['beta7'].shape == bn_model.bias.data.shape) and self.b == \"bb\":\n",
        "            scratch.params['beta7'] = bn_model.bias.data\n",
        "            with open('./weight_parameter/bn_param/bias/{}'.format(7), mode='w') as f:\n",
        "                f.write(str(bn_model.bias.data))\n",
        "\n",
        "        self.start = self.start + num_b\n",
        "\n",
        "        \n",
        "\n",
        "        bn_model.weight.data.copy_(\n",
        "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
        "\n",
        "\n",
        "        if bn_model.weight.data.shape == scratch.params['gamma0'].shape:\n",
        "            scratch.params['gamma0'] = bn_model.weight.data\n",
        "            with open('./weight_parameter/bn_param/gamma/{}'.format(0), mode='w') as f:\n",
        "                f.write(str(bn_model.weight.data))\n",
        "        elif bn_model.weight.data.shape == scratch.params['gamma1'].shape:\n",
        "            scratch.params['gamma1'] = bn_model.weight.data\n",
        "            with open('./weight_parameter/bn_param/gamma/{}'.format(1), mode='w') as f:\n",
        "                f.write(str(bn_model.weight.data))\n",
        "        elif bn_model.weight.data.shape == scratch.params['gamma2'].shape:\n",
        "            scratch.params['gamma2'] = bn_model.weight.data\n",
        "            with open('./weight_parameter/bn_param/gamma/{}'.format(2), mode='w') as f:\n",
        "                f.write(str(bn_model.weight.data))\n",
        "        elif bn_model.weight.data.shape == scratch.params['gamma3'].shape:\n",
        "            scratch.params['gamma3'] = bn_model.weight.data\n",
        "            with open('./weight_parameter/bn_param/gamma/{}'.format(3), mode='w') as f:\n",
        "                f.write(str(bn_model.weight.data))\n",
        "        elif bn_model.weight.data.shape == scratch.params['gamma4'].shape:\n",
        "            scratch.params['gamma4'] = bn_model.weight.data\n",
        "            with open('./weight_parameter/bn_param/gamma/{}'.format(4), mode='w') as f:\n",
        "                f.write(str(bn_model.weight.data))\n",
        "        elif bn_model.weight.data.shape == scratch.params['gamma5'].shape:\n",
        "            scratch.params['gamma5'] = bn_model.weight.data\n",
        "            with open('./weight_parameter/bn_param/gamma/{}'.format(5), mode='w') as f:\n",
        "                f.write(str(bn_model.weight.data))\n",
        "        elif (bn_model.weight.shape == scratch.params['gamma6'].shape) and self.g == \"g\":\n",
        "            scratch.params['gamma6'] = bn_model.weight.data\n",
        "            with open('./weight_parameter/bn_param/gamma/{}'.format(6), mode='w') as f:\n",
        "                f.write(str(bn_model.weight.data))\n",
        "            self.g = 'gg'\n",
        "        elif (scratch.params['gamma7'].shape == bn_model.weight.data.shape) and self.g == \"gg\":\n",
        "            scratch.params['gamma7'] = bn_model.weight.data\n",
        "            with open('./weight_parameter/bn_param/gamma/{}'.format(7), mode='w') as f:\n",
        "                f.write(str(bn_model.weight.data))\n",
        "\n",
        "        self.start = self.start + num_b\n",
        "\n",
        "        bn_model.running_mean.copy_(\n",
        "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
        "\n",
        "        if bn_model.running_mean.data.shape == scratch.bn_params[0]['running_mean'].shape:\n",
        "            scratch.bn_params[0]['running_mean'] = bn_model.running_mean.data\n",
        "            with open('./weight_parameter/bn_param/running_mean/{}'.format(0), mode='w') as f:\n",
        "                f.write(str(bn_model.running_mean.data))\n",
        "        elif bn_model.running_mean.data.shape == scratch.bn_params[1]['running_mean'].shape:\n",
        "            scratch.bn_params[1]['running_mean'] = bn_model.running_mean.data\n",
        "            with open('./weight_parameter/bn_param/running_mean/{}'.format(1), mode='w') as f:\n",
        "                f.write(str(bn_model.running_mean.data))\n",
        "        elif bn_model.running_mean.data.shape == scratch.bn_params[2]['running_mean'].shape:\n",
        "            scratch.bn_params[2]['running_mean'] = bn_model.running_mean.data\n",
        "            with open('./weight_parameter/bn_param/running_mean/{}'.format(2), mode='w') as f:\n",
        "                f.write(str(bn_model.running_mean.data))\n",
        "        elif bn_model.running_mean.data.shape == scratch.bn_params[3]['running_mean'].shape:\n",
        "            scratch.bn_params[3]['running_mean'] = bn_model.running_mean.data\n",
        "            with open('./weight_parameter/bn_param/running_mean/{}'.format(3), mode='w') as f:\n",
        "                f.write(str(bn_model.running_mean.data))\n",
        "        elif bn_model.running_mean.data.shape == scratch.bn_params[4]['running_mean'].shape:\n",
        "            scratch.bn_params[4]['running_mean'] = bn_model.running_mean.data\n",
        "            with open('./weight_parameter/bn_param/running_mean/{}'.format(4), mode='w') as f:\n",
        "                f.write(str(bn_model.running_mean.data))\n",
        "        elif bn_model.running_mean.data.shape == scratch.bn_params[5]['running_mean'].shape:\n",
        "            scratch.bn_params[5]['running_mean'] = bn_model.running_mean.data\n",
        "            with open('./weight_parameter/bn_param/running_mean/{}'.format(5), mode='w') as f:\n",
        "                f.write(str(bn_model.running_mean.data))\n",
        "        elif bn_model.running_mean.data.shape == scratch.bn_params[6]['running_mean'].shape and self.rm == \"rm\":\n",
        "            scratch.bn_params[6]['running_mean'] = bn_model.running_mean.data\n",
        "            with open('./weight_parameter/bn_param/running_mean/{}'.format(6), mode='w') as f:\n",
        "                f.write(str(bn_model.running_mean.data))\n",
        "            self.rm = \"rmrm\"\n",
        "        elif bn_model.running_mean.data.shape == scratch.bn_params[7]['running_mean'].shape and self.rm == \"rmrm\":\n",
        "            scratch.bn_params[7]['running_mean'] = bn_model.running_mean.data\n",
        "            with open('./weight_parameter/bn_param/running_mean/{}'.format(7), mode='w') as f:\n",
        "                f.write(str(bn_model.running_mean.data))\n",
        "\n",
        "        self.start = self.start + num_b\n",
        "\n",
        "        bn_model.running_var.copy_(\n",
        "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
        "\n",
        "        if bn_model.running_var.data.shape == scratch.bn_params[0]['running_var'].shape:\n",
        "            scratch.bn_params[0]['running_var'] = bn_model.running_var.data\n",
        "            with open('./weight_parameter/bn_param/running_var/{}'.format(0), mode='w') as f:\n",
        "                f.write(str(bn_model.running_var.data))\n",
        "        elif bn_model.running_var.data.shape == scratch.bn_params[1]['running_var'].shape:\n",
        "            scratch.bn_params[1]['running_var'] = bn_model.running_var.data\n",
        "            with open('./weight_parameter/bn_param/running_var/{}'.format(1), mode='w') as f:\n",
        "                f.write(str(bn_model.running_var.data))\n",
        "        elif bn_model.running_var.data.shape == scratch.bn_params[2]['running_var'].shape:\n",
        "            scratch.bn_params[2]['running_var'] = bn_model.running_var.data\n",
        "            with open('./weight_parameter/bn_param/running_var/{}'.format(2), mode='w') as f:\n",
        "                f.write(str(bn_model.running_var.data))\n",
        "        elif bn_model.running_var.data.shape == scratch.bn_params[3]['running_var'].shape:\n",
        "            scratch.bn_params[3]['running_var'] = bn_model.running_var.data\n",
        "            with open('./weight_parameter/bn_param/running_var/{}'.format(3), mode='w') as f:\n",
        "                f.write(str(bn_model.running_var.data))\n",
        "        elif bn_model.running_var.data.shape == scratch.bn_params[4]['running_var'].shape:\n",
        "            scratch.bn_params[4]['running_var'] = bn_model.running_var.data\n",
        "            with open('./weight_parameter/bn_param/running_var/{}'.format(4), mode='w') as f:\n",
        "                f.write(str(bn_model.running_var.data))\n",
        "        elif bn_model.running_var.data.shape == scratch.bn_params[5]['running_var'].shape:\n",
        "            scratch.bn_params[5]['running_var'] = bn_model.running_var.data\n",
        "            with open('./weight_parameter/bn_param/running_var/{}'.format(5), mode='w') as f:\n",
        "                f.write(str(bn_model.running_var.data))\n",
        "        elif bn_model.running_var.data.shape == scratch.bn_params[6]['running_var'].shape and self.rv == \"rv\":\n",
        "            scratch.bn_params[6]['running_var'] = bn_model.running_var.data\n",
        "            with open('./weight_parameter/bn_param/running_var/{}'.format(6), mode='w') as f:\n",
        "                f.write(str(bn_model.running_var.data))\n",
        "            self.rv = \"rvrv\"\n",
        "        elif bn_model.running_var.data.shape == scratch.bn_params[7]['running_var'].shape and self.rv == \"rvrv\":\n",
        "            scratch.bn_params[7]['running_var'] = bn_model.running_var.data\n",
        "            with open('./weight_parameter/bn_param/running_var/{}'.format(7), mode='w') as f:\n",
        "                f.write(str(bn_model.running_var.data))\n",
        "            \n",
        "        self.start = self.start + num_b\n",
        "\n",
        "        conv_model.weight.data.copy_(\n",
        "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_w]), conv_model.weight.size()))\n",
        "        \n",
        "        \n",
        "        if conv_model.weight.data.shape == (16, 3, 3, 3):\n",
        "            scratch.params['W0'] = conv_model.weight.data\n",
        "            with open('./weight_parameter/conv_param/w/{}'.format(0), mode='w') as f:\n",
        "                f.write(str(conv_model.weight.data))\n",
        "        elif conv_model.weight.data.shape == (32, 16, 3, 3):\n",
        "            scratch.params['W1'] = conv_model.weight.data\n",
        "            with open('./weight_parameter/conv_param/w/{}'.format(1), mode='w') as f:\n",
        "                f.write(str(conv_model.weight.data))\n",
        "        elif conv_model.weight.data.shape == (64, 32, 3, 3):\n",
        "            scratch.params['W2'] = conv_model.weight.data\n",
        "            with open('./weight_parameter/conv_param/w/{}'.format(2), mode='w') as f:\n",
        "                f.write(str(conv_model.weight.data))\n",
        "        elif conv_model.weight.data.shape == (128, 64, 3, 3):\n",
        "            scratch.params['W3'] = conv_model.weight.data\n",
        "            with open('./weight_parameter/conv_param/w/{}'.format(3), mode='w') as f:\n",
        "                f.write(str(conv_model.weight.data))\n",
        "        elif conv_model.weight.data.shape == (256, 128, 3, 3):\n",
        "            scratch.params['W4'] = conv_model.weight.data\n",
        "            with open('./weight_parameter/conv_param/w/{}'.format(4), mode='w') as f:\n",
        "                f.write(str(conv_model.weight.data))\n",
        "        elif conv_model.weight.data.shape == (512, 256, 3, 3):\n",
        "            scratch.params['W5'] = conv_model.weight.data\n",
        "            with open('./weight_parameter/conv_param/w/{}'.format(5), mode='w') as f:\n",
        "                f.write(str(conv_model.weight.data))\n",
        "        elif conv_model.weight.data.shape == (1024, 512, 3, 3):            \n",
        "            scratch.params['W6'] = conv_model.weight.data\n",
        "            with open('./weight_parameter/conv_param/w/{}'.format(6), mode='w') as f:\n",
        "                f.write(str(conv_model.weight.data))\n",
        "        elif conv_model.weight.data.shape == (1024, 1024, 3, 3):\n",
        "            scratch.params['W7'] = conv_model.weight.data\n",
        "            with open('./weight_parameter/conv_param/w/{}'.format(7), mode='w') as f:\n",
        "                f.write(str(conv_model.weight.data))\n",
        "        self.start = self.start + num_w\n",
        "\n",
        "    def load_conv(self, conv_model):\n",
        "        num_w = conv_model.weight.numel()\n",
        "        num_b = conv_model.bias.numel()\n",
        "        conv_model.bias.data.copy_(\n",
        "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), conv_model.bias.size()))\n",
        "        scratch.params['b8'] = conv_model.bias.data\n",
        "        with open('./weight_parameter/bias/{}'.format(7), mode='w') as f:\n",
        "            f.write(str(conv_model.bias.data))\n",
        "        self.start = self.start + num_b\n",
        "        conv_model.weight.data.copy_(\n",
        "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_w]), conv_model.weight.size()))\n",
        "        scratch.params['W8'] = conv_model.weight.data\n",
        "        with open('./weight_parameter/conv_param/w/{}'.format(8), mode='w') as f:\n",
        "            f.write(str(conv_model.weight.data))\n",
        "        self.start = self.start + num_w\n",
        "\n",
        "    def dfs(self, m):\n",
        "        children = list(m.children())\n",
        "        for i, c in enumerate(children):\n",
        "            if isinstance(c, torch.nn.Sequential):\n",
        "                self.dfs(c)\n",
        "            elif isinstance(c, torch.nn.Conv2d):\n",
        "                if c.bias is not None:\n",
        "                    self.load_conv(c)\n",
        "                else:\n",
        "                    self.load_conv_bn(c, children[i + 1])\n",
        "\n",
        "    def load(self, model, weights_file):\n",
        "        self.start = 0\n",
        "        fp = open(weights_file, 'rb')\n",
        "        header = np.fromfile(fp, count=4, dtype=np.int32)\n",
        "        self.buf = np.fromfile(fp, dtype=np.float32)\n",
        "        fp.close()\n",
        "        size = self.buf.size\n",
        "        self.dfs(model)\n",
        "        # make sure the loaded weight is right\n",
        "    \n",
        "        assert size == self.start\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "I-725DWZTpo6",
        "outputId": "19e9c008-fb83-4b29-f869-e7d8e7c2b63c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "# Importing libraries\n",
        "\n",
        "from matplotlib.pyplot import *\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import os\n",
        "import mnist\n",
        "from torch.cuda import amp\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
        "device = \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iAoYBSKmWKWE"
      },
      "outputs": [],
      "source": [
        "# Define Model\n",
        "class simple_network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(simple_network, self).__init__()\n",
        "        self.conv0   = nn.Conv2d    (   1,  8,   kernel_size=(3, 3),     bias=False  , padding=1)   \n",
        "        self.max0    = nn.MaxPool2d (            kernel_size=(2,2)                   )   \n",
        "        self.conv1   = nn.Conv2d    (   8,  16,  kernel_size=(3, 3),     bias=False , padding=1 )   \n",
        "        self.max1    = nn.MaxPool2d (            kernel_size=(2,2)                   )   \n",
        "        self.flat    = nn.Flatten   (                                                )   \n",
        "        self.linear0 = nn.Linear    (            784,  784                           )\n",
        "        self.linear1 = nn.Linear    (            784,  10                            )\n",
        "        self.soft    = nn.Softmax   (            dim=1                               )\n",
        "        \n",
        "        self.debug=False\n",
        "        \n",
        "\n",
        "    def forward(self,x):\n",
        "        x=x.to(torch.device(\"cpu\"))\n",
        "        x_conv0      = self.conv0     (   x              )  \n",
        "        x_max0       = self.max0      (   x_conv0        )\n",
        "        x_conv1      = self.conv1     (   x_max0         )  \n",
        "        x_max1       = self.max1      (   x_conv1        )\n",
        "        x_flat       = self.flat      (   x_max1         )\n",
        "        x_linear0    = self.linear0   (   x_flat         )\n",
        "        x_linear1    = self.linear1   (   x_linear0      )\n",
        "        x_prob       = self.soft      (   x_linear1      )\n",
        "\n",
        "        # TODO: Fix Learning Rate and Gradient Descent Method, check batch size\n",
        "        if self.debug:\n",
        "            im=x[0][0]\n",
        "            print(f\"Input Image: {im[-4]}\\n\")\n",
        "            \n",
        "            print(f\"conv0 filters: {model.state_dict()['conv0.weight'][0][0]}\\n\")\n",
        "            \n",
        "            print(f\"x_conv0 : {x_conv0[0,0,:,:][-1]}\\n\")\n",
        "\n",
        "            print(f\"MaxPool0: {x_max0[0,0][-1]}\\n\")\n",
        "            \n",
        "            print(f\"conv1 filters: {model.state_dict()['conv1.weight'][0][0]}\\n\")\n",
        "            \n",
        "            print(f\"x_conv1 : {x_conv1[0,0,:,:][-1]}\\n\")\n",
        "\n",
        "            print(f\"MaxPool1: {x_max1[0,0][-1]}\\n\")\n",
        "            \n",
        "            print(f\"FC0 Weight: {model.state_dict()['linear0.weight'][0][:10]}\\n\")\n",
        "            \n",
        "            print(f\"FC0 Output: {x_linear0[0,:10]}\\n\")\n",
        "            \n",
        "            print(f\"FC1 Weight: {model.state_dict()['linear1.weight'][0][:10]}\\n\")\n",
        "            \n",
        "            print(f\"FC1 Output: {x_linear1[0,:10]}\\n\")\n",
        "            \n",
        "            print(f\"SoftMax Output: {x_prob}\\n\")\n",
        "            \n",
        "        return x_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mqYZeDDpU8B4",
        "outputId": "6fbe1782-9cb5-4e15-dbf9-b241f5749f28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "simple_network(\n",
            "  (conv0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (max0): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (max1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear0): Linear(in_features=784, out_features=784, bias=True)\n",
            "  (linear1): Linear(in_features=784, out_features=10, bias=True)\n",
            "  (soft): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Initialize model and print\n",
        "\n",
        "model = simple_network()\n",
        "model.double()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_YL3A_cuU8B5"
      },
      "outputs": [],
      "source": [
        "# Hyper Parameters\n",
        "\n",
        "n_epochs = 3\n",
        "# batch_size_train = 64\n",
        "# batch_size_test = 1000\n",
        "learning_rate = 0.005\n",
        "momentum = 0\n",
        "log_interval = 1\n",
        "torch.backends.cudnn.enabled = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YMC2OtZsU8B6"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=momentum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jBCvlbF3U8B6",
        "outputId": "9d624884-2590-40fe-cc07-0a072928acda"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gpuadmin/.local/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
          ]
        }
      ],
      "source": [
        "# Scaler\n",
        "scaler = amp.GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cfnxm2MUU8B9"
      },
      "outputs": [],
      "source": [
        "# Loss Function\n",
        "calculate_loss = nn.CrossEntropyLoss()\n",
        "# calculate_loss_nlll = nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8qQYj2N3U8B_"
      },
      "outputs": [],
      "source": [
        "# Define Dataset\n",
        "train_images = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "test_images = mnist.test_images()\n",
        "test_labels = mnist.test_labels()\n",
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n",
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "test_images = np.expand_dims(test_images, axis=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eHQfoTeNU8CC"
      },
      "outputs": [],
      "source": [
        "# Counters to keep track of losses\n",
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_labels) for i in range(n_epochs + 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SuSyIPjHU8CE"
      },
      "outputs": [],
      "source": [
        "# Function for copying weights from basic model \n",
        "def copy_weights():\n",
        "    # TODO: To copy filter weights\n",
        "    name = \"weights/debug.pkl\"\n",
        "    print(f\"Loading weights from {name}\")\n",
        "    weight_file = open(name, \"rb\")\n",
        "    weights = pickle.load(weight_file)\n",
        "    print(f\"\\nLoading weights from {name} file\")\n",
        "    \n",
        "    fconv0   = weights[\"conv0\"]  \n",
        "    fconv1   = weights[\"conv1\"]  \n",
        "    flinear0 = weights[\"fc0_weights\"]\n",
        "    blinear0 = weights[\"fc0_biases\" ]\n",
        "    flinear1 = weights[\"fc1_weights\"]\n",
        "    blinear1 = weights[\"fc1_biases\" ]\n",
        "\n",
        "    debug=False\n",
        "    for i in range(fconv0.shape[0]):\n",
        "        model.state_dict()['conv0.weight'][i][0]     = torch.from_numpy(fconv0[i]).double()\n",
        "        if debug: print(f\"Weights for Conv0 Filter {i} are {model.state_dict()['conv0.weight'][i][0][0]}   \")\n",
        "\n",
        "    for i in range(fconv1.shape[0]):\n",
        "        for j in range(fconv1.shape[3]):\n",
        "            model.state_dict()['conv1.weight'][i,j,:,:]     = torch.from_numpy(fconv1[i,:,:,j]).double()\n",
        "        if debug: print(f\"Weights for Conv1 Filter {i} are {model.state_dict()['conv1.weight'][i][0][0]}   \")\n",
        "\n",
        "    for i in range(flinear0.shape[1]):\n",
        "        model.state_dict()['linear0.weight'][i]      = torch.from_numpy(flinear0[:,i]).double()\n",
        "        if debug and i<10: print(f\"Weights for Linear Filter {i} are {model.state_dict()['linear0.weight'][i][:5]} \")\n",
        "        \n",
        "    for i in range(blinear0.shape[0]):\n",
        "        model.state_dict()['linear0.bias'][i]        = torch.tensor(blinear0[i]).double()\n",
        "        if debug and i<10: print(f\"Weights for Linear Bias   {i} are {model.state_dict()['linear0.bias'][i]}   \")\n",
        "    \n",
        "    for i in range(flinear1.shape[1]):\n",
        "        model.state_dict()['linear1.weight'][i]      = torch.from_numpy(flinear1[:,i]).double()\n",
        "        if debug and i<10: print(f\"Weights for Linear Filter {i} are {model.state_dict()['linear1.weight'][i][:5]} \")\n",
        "        \n",
        "    for i in range(blinear1.shape[0]):\n",
        "        model.state_dict()['linear1.bias'][i]        = torch.tensor(blinear1[i]).double()\n",
        "        if debug and i<10: print(f\"Weights for Linear Bias   {i} are {model.state_dict()['linear1.bias'][i]}   \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qnbpVtumU8CF"
      },
      "outputs": [],
      "source": [
        "# Define the Train function\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    model.double()\n",
        "    copy_weights()\n",
        "    for batch_idx, (image, target) in enumerate(zip(train_images,train_labels)):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Prepare Image\n",
        "        img_numpy  = image[:,:,0]\n",
        "        img_tensor = torch.tensor(img_numpy).double()\n",
        "        img_for_model = img_tensor.unsqueeze(0).unsqueeze(0).double()\n",
        "\n",
        "        # Prepare label\n",
        "        label_vector = torch.zeros(1,10)\n",
        "        label_vector[:,target]=1\n",
        "\n",
        "        # Model Output\n",
        "        output = model(img_for_model.double())\n",
        "        \n",
        "        # Calculate Loss\n",
        "        loss = calculate_loss(label_vector, output)\n",
        "        # loss_nlll = calculate_loss_nlll(label_vector, output)\n",
        "        \n",
        "        # Calculate gradients\n",
        "        # scaler.scale(loss).backward()\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update weights\n",
        "        # optimizer.step()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        grad_bank = {}\n",
        "        for idx, param in enumerate(model.parameters()):\n",
        "            # print(f\"Parameter: {param.name}\")\n",
        "            # print(f\"Parameter: {param.names}\")\n",
        "            # print(f\"Parameter: {param.grad.data}\") \n",
        "            grad_bank[f\"layer_{idx}\"] = param.grad.data\n",
        "        \n",
        "        if model.debug: print(grad_bank['layer_5'])\n",
        "            \n",
        "            \n",
        "        # if batch_idx % log_interval == 0:\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(image), len(train_images),100. * batch_idx / len(train_images), loss.item()),end='\\r')\n",
        "        # train_losses.append(loss.item())\n",
        "        # train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
        "        # torch.save(network.state_dict(), '/results/model.pth')\n",
        "        # torch.save(optimizer.state_dict(), '/results/optimizer.pth')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wsiPLY0YU8CF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading weights from weights/debug.pkl\n",
            "\n",
            "Loading weights from weights/debug.pkl file\n",
            "Train Epoch: 1 [611548/60000 (36%)]\tLoss: 2.355356\r"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Run Training\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     train(epoch)    \n",
            "Cell \u001b[0;32mIn[12], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     22\u001b[0m loss \u001b[39m=\u001b[39m calculate_loss(label_vector, output)\n\u001b[1;32m     23\u001b[0m \u001b[39m# loss_nlll = calculate_loss_nlll(label_vector, output)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[39m# Calculate gradients\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m# scaler.scale(loss).backward()\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     29\u001b[0m \u001b[39m# Update weights\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# optimizer.step()\u001b[39;00m\n\u001b[1;32m     31\u001b[0m scaler\u001b[39m.\u001b[39mstep(optimizer)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Run Training\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    train(epoch)    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "python_cnn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "b9450f1e70c40e3e13ef2de08476fb3dcd992e7612be6477af641a838aca42a3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
