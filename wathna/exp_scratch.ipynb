{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wathna/anaconda3/envs/pytorch11-6/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from yolov2tiny import Yolov2\n",
    "import eecs598\n",
    "from cnn_scratch import DeepConvNet, Conv, ConvB, Conv_ReLU, Conv_ReLU_Pool, Conv_BatchNorm_ReLU, Conv_BatchNorm_ReLU_Pool\n",
    "from cnn_torch import FastConv, FastConvWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch = DeepConvNet(input_dims=(3, 416, 416),\n",
    "                        num_filters=[16, 32, 64, 128, 256, 512, 1024, 1024],\n",
    "                        max_pools=[0, 1, 2, 3, 4],\n",
    "                        weight_scale='kaiming',\n",
    "                        batchnorm=True,\n",
    "                        dtype=torch.float32, device='cpu')\n",
    "\n",
    "class WeightLoader(object):\n",
    "    def __init__(self):\n",
    "        super(WeightLoader, self).__init__()\n",
    "        self.start = 0\n",
    "        self.buf = None\n",
    "        self.b = 'b'\n",
    "        self.g = 'g'\n",
    "        self.rm = 'rm'\n",
    "        self.rv = 'rv'\n",
    "        \n",
    "    def load_conv_bn(self, conv_model, bn_model):\n",
    "\n",
    "        num_w = conv_model.weight.numel()\n",
    "        num_b = bn_model.bias.numel()\n",
    "\n",
    "        bn_model.bias.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "\n",
    "        if bn_model.bias.data.shape == scratch.params['beta0'].shape:\n",
    "            scratch.params['beta0'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(0), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "        elif bn_model.bias.data.shape == scratch.params['beta1'].shape:\n",
    "            scratch.params['beta1'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(1), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "        elif bn_model.bias.data.shape == scratch.params['beta2'].shape:\n",
    "            scratch.params['beta2'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(2), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "        elif bn_model.bias.data.shape == scratch.params['beta3'].shape:\n",
    "            scratch.params['beta3'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(3), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "        elif bn_model.bias.data.shape == scratch.params['beta4'].shape:\n",
    "            scratch.params['beta4'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(4), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "        elif bn_model.bias.data.shape == scratch.params['beta5'].shape:\n",
    "            scratch.params['beta5'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(5), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "        elif (bn_model.bias.data.shape == scratch.params['beta6'].shape) and self.b == \"b\":\n",
    "            scratch.params['beta6'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(6), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "            self.b = 'bb'\n",
    "        elif (scratch.params['beta7'].shape == bn_model.bias.data.shape) and self.b == \"bb\":\n",
    "            scratch.params['beta7'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(7), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "\n",
    "        self.start = self.start + num_b\n",
    "\n",
    "        \n",
    "\n",
    "        bn_model.weight.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "\n",
    "\n",
    "        if bn_model.weight.data.shape == scratch.params['gamma0'].shape:\n",
    "            scratch.params['gamma0'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(0), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "        elif bn_model.weight.data.shape == scratch.params['gamma1'].shape:\n",
    "            scratch.params['gamma1'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(1), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "        elif bn_model.weight.data.shape == scratch.params['gamma2'].shape:\n",
    "            scratch.params['gamma2'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(2), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "        elif bn_model.weight.data.shape == scratch.params['gamma3'].shape:\n",
    "            scratch.params['gamma3'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(3), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "        elif bn_model.weight.data.shape == scratch.params['gamma4'].shape:\n",
    "            scratch.params['gamma4'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(4), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "        elif bn_model.weight.data.shape == scratch.params['gamma5'].shape:\n",
    "            scratch.params['gamma5'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(5), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "        elif (bn_model.weight.shape == scratch.params['gamma6'].shape) and self.g == \"g\":\n",
    "            scratch.params['gamma6'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(6), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "            self.g = 'gg'\n",
    "        elif (scratch.params['gamma7'].shape == bn_model.weight.data.shape) and self.g == \"gg\":\n",
    "            scratch.params['gamma7'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(7), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "\n",
    "        self.start = self.start + num_b\n",
    "\n",
    "        bn_model.running_mean.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "\n",
    "        if bn_model.running_mean.data.shape == scratch.bn_params[0]['running_mean'].shape:\n",
    "            scratch.bn_params[0]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(0), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[1]['running_mean'].shape:\n",
    "            scratch.bn_params[1]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(1), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[2]['running_mean'].shape:\n",
    "            scratch.bn_params[2]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(2), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[3]['running_mean'].shape:\n",
    "            scratch.bn_params[3]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(3), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[4]['running_mean'].shape:\n",
    "            scratch.bn_params[4]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(4), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[5]['running_mean'].shape:\n",
    "            scratch.bn_params[5]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(5), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[6]['running_mean'].shape and self.rm == \"rm\":\n",
    "            scratch.bn_params[6]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(6), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "            self.rm = \"rmrm\"\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[7]['running_mean'].shape and self.rm == \"rmrm\":\n",
    "            scratch.bn_params[7]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(7), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "\n",
    "        self.start = self.start + num_b\n",
    "\n",
    "        bn_model.running_var.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "\n",
    "        if bn_model.running_var.data.shape == scratch.bn_params[0]['running_var'].shape:\n",
    "            scratch.bn_params[0]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(0), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[1]['running_var'].shape:\n",
    "            scratch.bn_params[1]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(1), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[2]['running_var'].shape:\n",
    "            scratch.bn_params[2]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(2), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[3]['running_var'].shape:\n",
    "            scratch.bn_params[3]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(3), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[4]['running_var'].shape:\n",
    "            scratch.bn_params[4]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(4), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[5]['running_var'].shape:\n",
    "            scratch.bn_params[5]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(5), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[6]['running_var'].shape and self.rv == \"rv\":\n",
    "            scratch.bn_params[6]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(6), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "            self.rv = \"rvrv\"\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[7]['running_var'].shape and self.rv == \"rvrv\":\n",
    "            scratch.bn_params[7]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(7), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "            \n",
    "        self.start = self.start + num_b\n",
    "\n",
    "        conv_model.weight.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_w]), conv_model.weight.size()))\n",
    "        \n",
    "        \n",
    "        if conv_model.weight.data.shape == (16, 3, 3, 3):\n",
    "            scratch.params['W0'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(0), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (32, 16, 3, 3):\n",
    "            scratch.params['W1'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(1), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (64, 32, 3, 3):\n",
    "            scratch.params['W2'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(2), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (128, 64, 3, 3):\n",
    "            scratch.params['W3'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(3), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (256, 128, 3, 3):\n",
    "            scratch.params['W4'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(4), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (512, 256, 3, 3):\n",
    "            scratch.params['W5'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(5), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (1024, 512, 3, 3):            \n",
    "            scratch.params['W6'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(6), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (1024, 1024, 3, 3):\n",
    "            scratch.params['W7'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(7), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        self.start = self.start + num_w\n",
    "\n",
    "    def load_conv(self, conv_model):\n",
    "        num_w = conv_model.weight.numel()\n",
    "        num_b = conv_model.bias.numel()\n",
    "        conv_model.bias.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), conv_model.bias.size()))\n",
    "        scratch.params['b8'] = conv_model.bias.data\n",
    "        with open('./weight_parameter/bias/{}'.format(7), mode='w') as f:\n",
    "            f.write(str(conv_model.bias.data))\n",
    "        self.start = self.start + num_b\n",
    "        conv_model.weight.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_w]), conv_model.weight.size()))\n",
    "        scratch.params['W8'] = conv_model.weight.data\n",
    "        with open('./weight_parameter/conv_param/w/{}'.format(8), mode='w') as f:\n",
    "            f.write(str(conv_model.weight.data))\n",
    "        self.start = self.start + num_w\n",
    "\n",
    "    def dfs(self, m):\n",
    "        children = list(m.children())\n",
    "        for i, c in enumerate(children):\n",
    "            if isinstance(c, torch.nn.Sequential):\n",
    "                self.dfs(c)\n",
    "            elif isinstance(c, torch.nn.Conv2d):\n",
    "                if c.bias is not None:\n",
    "                    self.load_conv(c)\n",
    "                else:\n",
    "                    self.load_conv_bn(c, children[i + 1])\n",
    "\n",
    "    def load(self, model, weights_file):\n",
    "        self.start = 0\n",
    "        fp = open(weights_file, 'rb')\n",
    "        header = np.fromfile(fp, count=4, dtype=np.int32)\n",
    "        self.buf = np.fromfile(fp, dtype=np.float32)\n",
    "        fp.close()\n",
    "        size = self.buf.size\n",
    "        self.dfs(model)\n",
    "        # make sure the loaded weight is right\n",
    "    \n",
    "        assert size == self.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weight_loader import WeightLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch = DeepConvNet(input_dims=(3, 416, 416),\n",
    "                        num_filters=[16, 32, 64, 128, 256, 512, 1024, 1024],\n",
    "                        max_pools=[0, 1, 2, 3, 4],\n",
    "                        weight_scale='kaiming',\n",
    "                        batchnorm=True,\n",
    "                        dtype=torch.float32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Yolov2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scratch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wathna/Downloads/Python_CNN/Python_CNN/wathna/exp_scratch.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wathna/Downloads/Python_CNN/Python_CNN/wathna/exp_scratch.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m weightloader \u001b[39m=\u001b[39m WeightLoader()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wathna/Downloads/Python_CNN/Python_CNN/wathna/exp_scratch.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m weightloader\u001b[39m.\u001b[39;49mload(model, \u001b[39m'\u001b[39;49m\u001b[39m./yolov2-tiny-voc.weights\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Downloads/Python_CNN/Python_CNN/wathna/weight_loader.py:254\u001b[0m, in \u001b[0;36mWeightLoader.load\u001b[0;34m(self, model, weights_file)\u001b[0m\n\u001b[1;32m    252\u001b[0m fp\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    253\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf\u001b[39m.\u001b[39msize\n\u001b[0;32m--> 254\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdfs(model)\n\u001b[1;32m    255\u001b[0m \u001b[39m# make sure the loaded weight is right\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[39massert\u001b[39;00m size \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart\n",
      "File \u001b[0;32m~/Downloads/Python_CNN/Python_CNN/wathna/weight_loader.py:245\u001b[0m, in \u001b[0;36mWeightLoader.dfs\u001b[0;34m(self, m)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_conv(c)\n\u001b[1;32m    244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_conv_bn(c, children[i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m])\n",
      "File \u001b[0;32m~/Downloads/Python_CNN/Python_CNN/wathna/weight_loader.py:26\u001b[0m, in \u001b[0;36mWeightLoader.load_conv_bn\u001b[0;34m(self, conv_model, bn_model)\u001b[0m\n\u001b[1;32m     21\u001b[0m num_b \u001b[39m=\u001b[39m bn_model\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mnumel()\n\u001b[1;32m     23\u001b[0m bn_model\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcopy_(\n\u001b[1;32m     24\u001b[0m     torch\u001b[39m.\u001b[39mreshape(torch\u001b[39m.\u001b[39mfrom_numpy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart \u001b[39m+\u001b[39m num_b]), bn_model\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39msize()))\n\u001b[0;32m---> 26\u001b[0m \u001b[39mif\u001b[39;00m bn_model\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m scratch\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mbeta0\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape:\n\u001b[1;32m     27\u001b[0m     scratch\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mbeta0\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m bn_model\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mdata\n\u001b[1;32m     28\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m./weight_parameter/bn_param/bias/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m0\u001b[39m), mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scratch' is not defined"
     ]
    }
   ],
   "source": [
    "weightloader = WeightLoader()\n",
    "weightloader.load(model, './yolov2-tiny-voc.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 416, 416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wathna/Downloads/Python_CNN/Python_CNN/wathna/exp_scratch.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wathna/Downloads/Python_CNN/Python_CNN/wathna/exp_scratch.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m output_scratch \u001b[39m=\u001b[39m scratch\u001b[39m.\u001b[39mloss(x)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "output_scratch = scratch.loss(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wathna/Downloads/Python_CNN/Python_CNN/wathna/exp_scratch.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wathna/Downloads/Python_CNN/Python_CNN/wathna/exp_scratch.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m output_torch \u001b[39m=\u001b[39m model(x)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "output_torch = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_scratch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wathna/Downloads/Python_CNN/Python_CNN/wathna/exp_scratch.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wathna/Downloads/Python_CNN/Python_CNN/wathna/exp_scratch.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(eecs598\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mrel_error(output_scratch[\u001b[39m0\u001b[39m], output_torch[\u001b[39m0\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_scratch' is not defined"
     ]
    }
   ],
   "source": [
    "print(eecs598.grad.rel_error(output_scratch[0], output_torch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f85ec04c150>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 5, 5])\n",
      "Testing Conv.backward function\n",
      "dx error:  7.937759210108112e-17\n",
      "dw error:  1.6172623953115152e-16\n",
      "db error:  1.643682260085236e-16\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "x = torch.randn(4, 3, 5, 5, dtype=torch.float64, device='cuda')\n",
    "w = torch.randn(2, 3, 3, 3, dtype=torch.float64, device='cuda')\n",
    "b = torch.randn(2, dtype=torch.float64, device='cuda')\n",
    "dout = torch.randn(4, 2, 5, 5, dtype=torch.float64, device='cuda')\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "dx_num = eecs598.grad.compute_numeric_gradient(lambda x: ConvB.forward(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eecs598.grad.compute_numeric_gradient(lambda w: ConvB.forward(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eecs598.grad.compute_numeric_gradient(lambda b: ConvB.forward(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "out, cache = ConvB.forward(x, w, b, conv_param)\n",
    "dx, dw, db = ConvB.backward(dout, cache)\n",
    "\n",
    "out2, cache2 = FastConvWB.forward(x, w, b, conv_param)\n",
    "dx2, dw2, db2 = FastConvWB.backward(dout, cache2)\n",
    "\n",
    "print('Testing Conv.backward function')\n",
    "print('dx error: ', eecs598.grad.rel_error(dx, dx2))\n",
    "print('dw error: ', eecs598.grad.rel_error(dw, dw2))\n",
    "print('db error: ', eecs598.grad.rel_error(db, db2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.6257, -0.4187, -2.4857, -2.1869, -0.1971], device='cuda:0',\n",
      "       dtype=torch.float64) tensor([ 1.6257, -0.4187, -2.4857, -2.1869, -0.1971], device='cuda:0',\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(dx[0, 0, 0, :], dx2[0, 0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.112923100512273e-08"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "x = torch.rand(1, 1, 12, 12)\n",
    "w = torch.randn(3, 1, 3, 3)\n",
    "nn.init.ones_(w)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "out, cache = Conv.forward(x, w, conv_param)\n",
    "# model = nn.Conv2d(1, 3, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "# if isinstance(model, nn.Conv2d):\n",
    "#     nn.init.ones_(model.weight)\n",
    "out2, cache2 = FastConv.forward(x, w, conv_param)\n",
    "eecs598.grad.rel_error(out, out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, w, conv_param = cache\n",
    "x2, w2, conv_param, tx, out2, layer = cache2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 12, 12]) torch.Size([1, 1, 12, 12])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (14) must match the size of tensor b (12) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/wathna/Downloads/Python_CNN/Python_CNN/wathna/exp_scratch.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wathna/Downloads/Python_CNN/Python_CNN/wathna/exp_scratch.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m eecs598\u001b[39m.\u001b[39;49mgrad\u001b[39m.\u001b[39;49mrel_error(x, x2)\n",
      "File \u001b[0;32m~/Downloads/Python_CNN/Python_CNN/wathna/eecs598/grad.py:120\u001b[0m, in \u001b[0;36mrel_error\u001b[0;34m(x, y, eps)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mCompute the relative error between a pair of tensors x and y,\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39mwhich is defined as:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m- rel_error: Scalar giving the relative error between x and y\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m\"\"\" returns relative error between x and y \"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m top \u001b[39m=\u001b[39m (x \u001b[39m-\u001b[39;49m y)\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmax()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    121\u001b[0m bot \u001b[39m=\u001b[39m (x\u001b[39m.\u001b[39mabs() \u001b[39m+\u001b[39m y\u001b[39m.\u001b[39mabs())\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39meps)\u001b[39m.\u001b[39mmax()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m top \u001b[39m/\u001b[39m bot\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (14) must match the size of tensor b (12) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "eecs598.grad.rel_error(x, x2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Conv_Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.205479032659077e-08"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 1, 12, 12)\n",
    "w = torch.randn(3, 1, 3, 3)\n",
    "nn.init.ones_(w)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "\n",
    "out, _ = Conv_ReLU.forward(x, w, conv_param)\n",
    "y = nn.Sequential(\n",
    "    nn.Conv2d(1, 3, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "    nn.LeakyReLU(0.1)\n",
    "    )\n",
    "for k in y.modules():\n",
    "    if isinstance(k, nn.Conv2d):\n",
    "        nn.init.ones_(k.weight)\n",
    "out2 = y(x)\n",
    "eecs598.grad.rel_error(out, out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.613768515865745e-08"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 1, 12, 12)\n",
    "w = torch.randn(3, 1, 3, 3)\n",
    "nn.init.ones_(w)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "out, _ = Conv_ReLU_Pool.forward(x, w, conv_param, pool_param)\n",
    "y = nn.Sequential(\n",
    "    nn.Conv2d(1, 3, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "for k in y.modules():\n",
    "    if isinstance(k, nn.Conv2d):\n",
    "        nn.init.ones_(k.weight)\n",
    "out2 = y(x)\n",
    "eecs598.grad.rel_error(out, out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Conv_BatchNorm_ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.30151624563296e-08"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 1, 12, 12)\n",
    "w = torch.randn(3, 1, 3, 3)\n",
    "nn.init.ones_(w)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "gamma = torch.ones(3)\n",
    "beta = torch.ones(3)\n",
    "bn_param = {'mode': 'train',\n",
    "            'running_mean': torch.ones(3),\n",
    "            'running_var': torch.ones(3)}\n",
    "\n",
    "out, _ = Conv_BatchNorm_ReLU.forward(x, w, gamma, beta, conv_param, bn_param)\n",
    "y = nn.Sequential(\n",
    "    nn.Conv2d(1, 3, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(3),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    )\n",
    "for k in y.modules():\n",
    "    if isinstance(k, nn.Conv2d):\n",
    "        nn.init.ones_(k.weight)\n",
    "    if isinstance(k, nn.BatchNorm2d):\n",
    "        nn.init.ones_(k.weight)\n",
    "        nn.init.ones_(k.bias)\n",
    "out2 = y(x)\n",
    "eecs598.grad.rel_error(out, out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Conv_BatchNorm_ReLU_Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3073163924551858e-07"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 1, 12, 12)\n",
    "w = torch.randn(3, 1, 3, 3)\n",
    "nn.init.ones_(w)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "gamma = torch.ones(3)\n",
    "beta = torch.ones(3)\n",
    "bn_param = {'mode': 'train',\n",
    "            'running_mean': torch.ones(3),\n",
    "            'running_var': torch.ones(3)}\n",
    "\n",
    "out, _ = Conv_BatchNorm_ReLU_Pool.forward(x, w, gamma, beta, conv_param, bn_param, pool_param)\n",
    "y = nn.Sequential(\n",
    "    nn.Conv2d(1, 3, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(3),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.MaxPool2d(2, 2)\n",
    "    )\n",
    "for k in y.modules():\n",
    "    if isinstance(k, nn.Conv2d):\n",
    "        nn.init.ones_(k.weight)\n",
    "    if isinstance(k, nn.BatchNorm2d):\n",
    "        nn.init.ones_(k.weight)\n",
    "        nn.init.ones_(k.bias)\n",
    "out2 = y(x)\n",
    "eecs598.grad.rel_error(out, out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch11-6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
