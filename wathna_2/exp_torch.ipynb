{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wathna/anaconda3/envs/pytorch11-6/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from yolov2tiny import Yolov2\n",
    "import eecs598\n",
    "from cnn_torch import DeepConvNetTorch, FastConv, FastConvWB, Conv_BatchNorm_ReLU, Conv_BatchNorm_ReLU_Pool, Conv_ReLU\n",
    "from cnn_scratch import DeepConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch = DeepConvNet(input_dims=(3, 416, 416),\n",
    "                        num_filters=[16, 32, 64, 128, 256, 512, 1024, 1024],\n",
    "                        max_pools=[0, 1, 2, 3, 4],\n",
    "                        weight_scale='kaiming',\n",
    "                        batchnorm=True,\n",
    "                        dtype=torch.float32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch = DeepConvNetTorch(input_dims=(3, 416, 416),\n",
    "                        num_filters=[16, 32, 64, 128, 256, 512, 1024, 1024],\n",
    "                        max_pools=[0, 1, 2, 3, 4],\n",
    "                        weight_scale='kaiming',\n",
    "                        batchnorm=True,\n",
    "                        dtype=torch.float32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Yolov2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WeightLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wathna/Downloads/Python_CNN/Python_CNN/wathna_new/exp_torch.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wathna/Downloads/Python_CNN/Python_CNN/wathna_new/exp_torch.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m weightloader \u001b[39m=\u001b[39m WeightLoader()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wathna/Downloads/Python_CNN/Python_CNN/wathna_new/exp_torch.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m weightloader\u001b[39m.\u001b[39mload(model, \u001b[39m'\u001b[39m\u001b[39m./yolov2-tiny-voc.weights\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'WeightLoader' is not defined"
     ]
    }
   ],
   "source": [
    "weightloader = WeightLoader()\n",
    "weightloader.load(model, './yolov2-tiny-voc.weights')\n",
    "# weightloader.load(model, scratch_torch, './yolov2-tiny-voc.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 416, 416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 416, 416])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = torch.randn(64, 10, 4)\n",
    "gt_classes = torch.randn(64, 10)\n",
    "num_boxes = torch.randn(64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.4997, 0.5001, 1.0005, 1.0000],\n",
      "         [0.4996, 0.5000, 1.0009, 1.0022],\n",
      "         [0.5001, 0.4999, 0.9995, 1.0011],\n",
      "         ...,\n",
      "         [0.5002, 0.4998, 0.9994, 1.0012],\n",
      "         [0.4998, 0.4998, 1.0014, 1.0038],\n",
      "         [0.5006, 0.4996, 0.9986, 0.9997]]], grad_fn=<CatBackward0>), tensor([[[0.5005],\n",
      "         [0.5006],\n",
      "         [0.5002],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001],\n",
      "         [0.5005],\n",
      "         [0.5006],\n",
      "         [0.5003],\n",
      "         [0.4999],\n",
      "         [0.5001]]], grad_fn=<SigmoidBackward0>), tensor([[[0.0499, 0.0500, 0.0499,  ..., 0.0500, 0.0499, 0.0501],\n",
      "         [0.0499, 0.0499, 0.0501,  ..., 0.0501, 0.0500, 0.0500],\n",
      "         [0.0500, 0.0499, 0.0500,  ..., 0.0500, 0.0500, 0.0502],\n",
      "         ...,\n",
      "         [0.0500, 0.0499, 0.0500,  ..., 0.0500, 0.0500, 0.0502],\n",
      "         [0.0501, 0.0501, 0.0499,  ..., 0.0500, 0.0499, 0.0501],\n",
      "         [0.0501, 0.0500, 0.0500,  ..., 0.0500, 0.0499, 0.0499]]],\n",
      "       grad_fn=<SoftmaxBackward0>))\n"
     ]
    }
   ],
   "source": [
    "output_scratch = scratch.loss(x)\n",
    "print(output_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loss() got an unexpected keyword argument 'gt_boxes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wathna/Downloads/Python_CNN/Python_CNN/wathna_new/exp_torch.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wathna/Downloads/Python_CNN/Python_CNN/wathna_new/exp_torch.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m output_scratch \u001b[39m=\u001b[39m scratch\u001b[39m.\u001b[39;49mloss(x, y \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, gt_boxes\u001b[39m=\u001b[39;49mboxes, gt_classes\u001b[39m=\u001b[39;49mgt_classes, num_boxes\u001b[39m=\u001b[39;49mnum_boxes)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wathna/Downloads/Python_CNN/Python_CNN/wathna_new/exp_torch.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(output_scratch)\n",
      "\u001b[0;31mTypeError\u001b[0m: loss() got an unexpected keyword argument 'gt_boxes'"
     ]
    }
   ],
   "source": [
    "output_scratch = scratch.loss(x, y = 1, gt_boxes=boxes, gt_classes=gt_classes, num_boxes=num_boxes)\n",
    "print(output_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/wathna/Downloads/Python_CNN/Python_CNN/wathna_new/exp_torch.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wathna/Downloads/Python_CNN/Python_CNN/wathna_new/exp_torch.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m output_torch \u001b[39m=\u001b[39m scratch\u001b[39m.\u001b[39;49mloss(x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wathna/Downloads/Python_CNN/Python_CNN/wathna_new/exp_torch.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(output_torch)\n",
      "File \u001b[0;32m~/Downloads/Python_CNN/Python_CNN/wathna_new/cnn_torch.py:516\u001b[0m, in \u001b[0;36mDeepConvNetTorch.loss\u001b[0;34m(self, X, y, gt_boxes, gt_classes, num_boxes, training)\u001b[0m\n\u001b[1;32m    513\u001b[0m     f\u001b[39m.\u001b[39mwrite(\u001b[39mstr\u001b[39m(out))\n\u001b[1;32m    514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatchnorm:\n\u001b[1;32m    515\u001b[0m   \u001b[39m#print('batch_without_pool')\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m   out,cache[\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i)] \u001b[39m=\u001b[39m Conv_BatchNorm_ReLU\u001b[39m.\u001b[39;49mforward(out,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mW\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(i)], \n\u001b[1;32m    517\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mgamma\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(i)],\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mbeta\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(i)],conv_param,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn_params[i])\n\u001b[1;32m    518\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m./output_torch/conv_bn_relu\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i), mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    519\u001b[0m     f\u001b[39m.\u001b[39mwrite(\u001b[39mstr\u001b[39m(out))\n",
      "File \u001b[0;32m~/Downloads/Python_CNN/Python_CNN/wathna_new/cnn_torch.py:1109\u001b[0m, in \u001b[0;36mConv_BatchNorm_ReLU.forward\u001b[0;34m(x, w, gamma, beta, conv_param, bn_param)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m   1108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(x, w, gamma, beta, conv_param, bn_param):\n\u001b[0;32m-> 1109\u001b[0m   a, conv_cache \u001b[39m=\u001b[39m FastConv\u001b[39m.\u001b[39;49mforward(x, w, conv_param)\n\u001b[1;32m   1110\u001b[0m   an, bn_cache \u001b[39m=\u001b[39m SpatialBatchNorm\u001b[39m.\u001b[39mforward(a, gamma, beta, bn_param)\n\u001b[1;32m   1111\u001b[0m   out, relu_cache \u001b[39m=\u001b[39m ReLU\u001b[39m.\u001b[39mforward(an)\n",
      "File \u001b[0;32m~/Downloads/Python_CNN/Python_CNN/wathna_new/cnn_torch.py:968\u001b[0m, in \u001b[0;36mFastConv.forward\u001b[0;34m(x, w, conv_param)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    967\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(x, w, conv_param):\n\u001b[0;32m--> 968\u001b[0m   N, C, H, W \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mshape\n\u001b[1;32m    969\u001b[0m   F, _, HH, WW \u001b[39m=\u001b[39m w\u001b[39m.\u001b[39mshape\n\u001b[1;32m    970\u001b[0m   stride, pad \u001b[39m=\u001b[39m conv_param[\u001b[39m'\u001b[39m\u001b[39mstride\u001b[39m\u001b[39m'\u001b[39m], conv_param[\u001b[39m'\u001b[39m\u001b[39mpad\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "output_torch = scratch.loss(x)\n",
    "print(output_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_scratch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wathna/Downloads/Python_CNN/Python_CNN/wathna_new/exp_torch.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wathna/Downloads/Python_CNN/Python_CNN/wathna_new/exp_torch.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m eecs598\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mrel_error(output_scratch[\u001b[39m0\u001b[39m], output_torch[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_scratch' is not defined"
     ]
    }
   ],
   "source": [
    "eecs598.grad.rel_error(output_scratch[0], output_torch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eecs598.grad.rel_error(output_scratch[1], output_torch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eecs598.grad.rel_error(output_scratch[2], output_torch[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightLoader(object):\n",
    "    def __init__(self):\n",
    "        super(WeightLoader, self).__init__()\n",
    "        self.start = 0\n",
    "        self.buf = None\n",
    "        self.b = 'b'\n",
    "        self.g = 'g'\n",
    "        self.rm = 'rm'\n",
    "        self.rv = 'rv'\n",
    "        \n",
    "    def load_conv_bn(self, conv_model, bn_model):\n",
    "\n",
    "        num_w = conv_model.weight.numel()\n",
    "        num_b = bn_model.bias.numel()\n",
    "\n",
    "        bn_model.bias.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "\n",
    "        if bn_model.bias.data.shape == scratch.params['beta0'].shape:\n",
    "            scratch.params['beta0'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(0), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "        elif bn_model.bias.data.shape == scratch.params['beta1'].shape:\n",
    "            scratch.params['beta1'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(1), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "        elif bn_model.bias.data.shape == scratch.params['beta2'].shape:\n",
    "            scratch.params['beta2'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(2), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "        elif bn_model.bias.data.shape == scratch.params['beta3'].shape:\n",
    "            scratch.params['beta3'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(3), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "        elif bn_model.bias.data.shape == scratch.params['beta4'].shape:\n",
    "            scratch.params['beta4'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(4), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "        elif bn_model.bias.data.shape == scratch.params['beta5'].shape:\n",
    "            scratch.params['beta5'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(5), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "        elif (bn_model.bias.data.shape == scratch.params['beta6'].shape) and self.b == \"b\":\n",
    "            scratch.params['beta6'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(6), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "            self.b = 'bb'\n",
    "        elif (scratch.params['beta7'].shape == bn_model.bias.data.shape) and self.b == \"bb\":\n",
    "            scratch.params['beta7'] = bn_model.bias.data\n",
    "            with open('./weight_parameter/bn_param/bias/{}'.format(7), mode='w') as f:\n",
    "                f.write(str(bn_model.bias.data))\n",
    "\n",
    "        self.start = self.start + num_b\n",
    "\n",
    "        \n",
    "\n",
    "        bn_model.weight.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "\n",
    "\n",
    "        if bn_model.weight.data.shape == scratch.params['gamma0'].shape:\n",
    "            scratch.params['gamma0'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(0), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "        elif bn_model.weight.data.shape == scratch.params['gamma1'].shape:\n",
    "            scratch.params['gamma1'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(1), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "        elif bn_model.weight.data.shape == scratch.params['gamma2'].shape:\n",
    "            scratch.params['gamma2'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(2), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "        elif bn_model.weight.data.shape == scratch.params['gamma3'].shape:\n",
    "            scratch.params['gamma3'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(3), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "        elif bn_model.weight.data.shape == scratch.params['gamma4'].shape:\n",
    "            scratch.params['gamma4'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(4), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "        elif bn_model.weight.data.shape == scratch.params['gamma5'].shape:\n",
    "            scratch.params['gamma5'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(5), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "        elif (bn_model.weight.shape == scratch.params['gamma6'].shape) and self.g == \"g\":\n",
    "            scratch.params['gamma6'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(6), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "            self.g = 'gg'\n",
    "        elif (scratch.params['gamma7'].shape == bn_model.weight.data.shape) and self.g == \"gg\":\n",
    "            scratch.params['gamma7'] = bn_model.weight.data\n",
    "            with open('./weight_parameter/bn_param/gamma/{}'.format(7), mode='w') as f:\n",
    "                f.write(str(bn_model.weight.data))\n",
    "\n",
    "        self.start = self.start + num_b\n",
    "\n",
    "        bn_model.running_mean.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "\n",
    "        if bn_model.running_mean.data.shape == scratch.bn_params[0]['running_mean'].shape:\n",
    "            scratch.bn_params[0]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(0), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[1]['running_mean'].shape:\n",
    "            scratch.bn_params[1]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(1), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[2]['running_mean'].shape:\n",
    "            scratch.bn_params[2]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(2), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[3]['running_mean'].shape:\n",
    "            scratch.bn_params[3]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(3), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[4]['running_mean'].shape:\n",
    "            scratch.bn_params[4]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(4), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[5]['running_mean'].shape:\n",
    "            scratch.bn_params[5]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(5), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[6]['running_mean'].shape and self.rm == \"rm\":\n",
    "            scratch.bn_params[6]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(6), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "            self.rm = \"rmrm\"\n",
    "        elif bn_model.running_mean.data.shape == scratch.bn_params[7]['running_mean'].shape and self.rm == \"rmrm\":\n",
    "            scratch.bn_params[7]['running_mean'] = bn_model.running_mean.data\n",
    "            with open('./weight_parameter/bn_param/running_mean/{}'.format(7), mode='w') as f:\n",
    "                f.write(str(bn_model.running_mean.data))\n",
    "\n",
    "        self.start = self.start + num_b\n",
    "\n",
    "        bn_model.running_var.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "\n",
    "        if bn_model.running_var.data.shape == scratch.bn_params[0]['running_var'].shape:\n",
    "            scratch.bn_params[0]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(0), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[1]['running_var'].shape:\n",
    "            scratch.bn_params[1]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(1), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[2]['running_var'].shape:\n",
    "            scratch.bn_params[2]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(2), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[3]['running_var'].shape:\n",
    "            scratch.bn_params[3]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(3), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[4]['running_var'].shape:\n",
    "            scratch.bn_params[4]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(4), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[5]['running_var'].shape:\n",
    "            scratch.bn_params[5]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(5), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[6]['running_var'].shape and self.rv == \"rv\":\n",
    "            scratch.bn_params[6]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(6), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "            self.rv = \"rvrv\"\n",
    "        elif bn_model.running_var.data.shape == scratch.bn_params[7]['running_var'].shape and self.rv == \"rvrv\":\n",
    "            scratch.bn_params[7]['running_var'] = bn_model.running_var.data\n",
    "            with open('./weight_parameter/bn_param/running_var/{}'.format(7), mode='w') as f:\n",
    "                f.write(str(bn_model.running_var.data))\n",
    "            \n",
    "        self.start = self.start + num_b\n",
    "\n",
    "        conv_model.weight.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_w]), conv_model.weight.size()))\n",
    "        \n",
    "        \n",
    "        if conv_model.weight.data.shape == (16, 3, 3, 3):\n",
    "            scratch.params['W0'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(0), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (32, 16, 3, 3):\n",
    "            scratch.params['W1'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(1), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (64, 32, 3, 3):\n",
    "            scratch.params['W2'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(2), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (128, 64, 3, 3):\n",
    "            scratch.params['W3'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(3), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (256, 128, 3, 3):\n",
    "            scratch.params['W4'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(4), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (512, 256, 3, 3):\n",
    "            scratch.params['W5'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(5), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (1024, 512, 3, 3):            \n",
    "            scratch.params['W6'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(6), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        elif conv_model.weight.data.shape == (1024, 1024, 3, 3):\n",
    "            scratch.params['W7'] = conv_model.weight.data\n",
    "            with open('./weight_parameter/conv_param/w/{}'.format(7), mode='w') as f:\n",
    "                f.write(str(conv_model.weight.data))\n",
    "        self.start = self.start + num_w\n",
    "\n",
    "    def load_conv(self, conv_model):\n",
    "        num_w = conv_model.weight.numel()\n",
    "        num_b = conv_model.bias.numel()\n",
    "        conv_model.bias.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), conv_model.bias.size()))\n",
    "        scratch.params['b8'] = conv_model.bias.data\n",
    "        with open('./weight_parameter/bias/{}'.format(7), mode='w') as f:\n",
    "            f.write(str(conv_model.bias.data))\n",
    "        self.start = self.start + num_b\n",
    "        conv_model.weight.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_w]), conv_model.weight.size()))\n",
    "        scratch.params['W8'] = conv_model.weight.data\n",
    "        with open('./weight_parameter/conv_param/w/{}'.format(8), mode='w') as f:\n",
    "            f.write(str(conv_model.weight.data))\n",
    "        self.start = self.start + num_w\n",
    "\n",
    "    def dfs(self, m):\n",
    "        children = list(m.children())\n",
    "        for i, c in enumerate(children):\n",
    "            if isinstance(c, torch.nn.Sequential):\n",
    "                self.dfs(c)\n",
    "            elif isinstance(c, torch.nn.Conv2d):\n",
    "                if c.bias is not None:\n",
    "                    self.load_conv(c)\n",
    "                else:\n",
    "                    self.load_conv_bn(c, children[i + 1])\n",
    "\n",
    "    def load(self, model, weights_file):\n",
    "        self.start = 0\n",
    "        fp = open(weights_file, 'rb')\n",
    "        header = np.fromfile(fp, count=4, dtype=np.int32)\n",
    "        self.buf = np.fromfile(fp, dtype=np.float32)\n",
    "        fp.close()\n",
    "        size = self.buf.size\n",
    "        self.dfs(model)\n",
    "        # make sure the loaded weight is right\n",
    "    \n",
    "        assert size == self.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch11-6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
